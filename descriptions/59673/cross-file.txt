// Here are some relevant code fragments from other files of the repo:

// the below code fragment can be found in:
// libavcodec/mpegvideo_dec.c
// static inline void MPV_motion_lowres(MpegEncContext *s,
//                                      uint8_t *dest_y, uint8_t *dest_cb,
//                                      uint8_t *dest_cr,
//                                      int dir, uint8_t *const *ref_picture,
//                                      const h264_chroma_mc_func *pix_op)
// {
//     int mx, my;
//     int mb_x, mb_y;
//     const int lowres  = s->avctx->lowres;
//     const int block_s = 8 >>lowres;
// 
//     mb_x = s->mb_x;
//     mb_y = s->mb_y;
// 
//     switch (s->mv_type) {
//     case MV_TYPE_16X16:
//         mpeg_motion_lowres(s, dest_y, dest_cb, dest_cr,
//                            0, 0, 0,
//                            ref_picture, pix_op,
//                            s->mv[dir][0][0], s->mv[dir][0][1],
//                            2 * block_s, mb_y);
//         break;
//     case MV_TYPE_8X8:
//         mx = 0;
//         my = 0;
//         for (int i = 0; i < 4; i++) {
//             hpel_motion_lowres(s, dest_y + ((i & 1) + (i >> 1) *
//                                s->linesize) * block_s,
//                                ref_picture[0], 0, 0,
//                                (2 * mb_x + (i & 1)) * block_s,
//                                (2 * mb_y + (i >> 1)) * block_s,
//                                s->width, s->height, s->linesize,
//                                s->h_edge_pos >> lowres, s->v_edge_pos >> lowres,
//                                block_s, block_s, pix_op,
//                                s->mv[dir][i][0], s->mv[dir][i][1]);
// 
//             mx += s->mv[dir][i][0];
//             my += s->mv[dir][i][1];
//         }
// 
//         if (!CONFIG_GRAY || !(s->avctx->flags & AV_CODEC_FLAG_GRAY))
//             chroma_4mv_motion_lowres(s, dest_cb, dest_cr, ref_picture,
//                                      pix_op, mx, my);
//         break;
//     case MV_TYPE_FIELD:
//         if (s->picture_structure == PICT_FRAME) {
//             /* top field */
//             mpeg_motion_lowres(s, dest_y, dest_cb, dest_cr,
//                                1, 0, s->field_select[dir][0],
//                                ref_picture, pix_op,
//                                s->mv[dir][0][0], s->mv[dir][0][1],
//                                block_s, mb_y);
//             /* bottom field */
//             mpeg_motion_lowres(s, dest_y, dest_cb, dest_cr,
//                                1, 1, s->field_select[dir][1],
//                                ref_picture, pix_op,
//                                s->mv[dir][1][0], s->mv[dir][1][1],
//                                block_s, mb_y);
//         } else {
//             if (s->picture_structure != s->field_select[dir][0] + 1 &&
//                 s->pict_type != AV_PICTURE_TYPE_B && !s->first_field) {
//                 ref_picture = s->current_picture_ptr->f->data;
// 
//             }
//             mpeg_motion_lowres(s, dest_y, dest_cb, dest_cr,
//                                0, 0, s->field_select[dir][0],
//                                ref_picture, pix_op,
//                                s->mv[dir][0][0],
//                                s->mv[dir][0][1], 2 * block_s, mb_y >> 1);
//             }
//         break;
//     case MV_TYPE_16X8:
//         for (int i = 0; i < 2; i++) {
//             uint8_t *const *ref2picture;
// 
//             if (s->picture_structure == s->field_select[dir][i] + 1 ||
//                 s->pict_type == AV_PICTURE_TYPE_B || s->first_field) {
//                 ref2picture = ref_picture;
//             } else {
//                 ref2picture = s->current_picture_ptr->f->data;
//             }
// 
//             mpeg_motion_lowres(s, dest_y, dest_cb, dest_cr,
//                                0, 0, s->field_select[dir][i],
//                                ref2picture, pix_op,
//                                s->mv[dir][i][0], s->mv[dir][i][1] +
//                                2 * block_s * i, block_s, mb_y >> 1);
// 
//             dest_y  +=  2 * block_s *  s->linesize;
//             dest_cb += (2 * block_s >> s->chroma_y_shift) * s->uvlinesize;
//             dest_cr += (2 * block_s >> s->chroma_y_shift) * s->uvlinesize;
//         }
//         break;
//     case MV_TYPE_DMV:
//         if (s->picture_structure == PICT_FRAME) {
//             for (int i = 0; i < 2; i++) {
//                 for (int j = 0; j < 2; j++) {
//                     mpeg_motion_lowres(s, dest_y, dest_cb, dest_cr,
//                                        1, j, j ^ i,
//                                        ref_picture, pix_op,
//                                        s->mv[dir][2 * i + j][0],
//                                        s->mv[dir][2 * i + j][1],
//                                        block_s, mb_y);
//                 }
//                 pix_op = s->h264chroma.avg_h264_chroma_pixels_tab;
//             }
//         } else {
//             for (int i = 0; i < 2; i++) {
//                 mpeg_motion_lowres(s, dest_y, dest_cb, dest_cr,
//                                    0, 0, s->picture_structure != i + 1,
//                                    ref_picture, pix_op,
//                                    s->mv[dir][2 * i][0],s->mv[dir][2 * i][1],
//                                    2 * block_s, mb_y >> 1);
// 
//                 // after put we make avg of the same block
//                 pix_op = s->h264chroma.avg_h264_chroma_pixels_tab;
// 
//                 // opposite parity is always in the same
//                 // frame if this is second field
//                 if (!s->first_field) {
//                     ref_picture = s->current_picture_ptr->f->data;
//                 }
//             }
//         }
//         break;
//     default:
//         av_assert2(0);
//     }
// }

// the below code fragment can be found in:
// libavcodec/mpegvideo_dec.c
// static inline void chroma_4mv_motion_lowres(MpegEncContext *s,
//                                             uint8_t *dest_cb, uint8_t *dest_cr,
//                                             uint8_t *const *ref_picture,
//                                             const h264_chroma_mc_func * pix_op,
//                                             int mx, int my)
// {
//     const int lowres     = s->avctx->lowres;
//     const int op_index   = FFMIN(lowres, 3);
//     const int block_s    = 8 >> lowres;
//     const int s_mask     = (2 << lowres) - 1;
//     const int h_edge_pos = s->h_edge_pos >> lowres + 1;
//     const int v_edge_pos = s->v_edge_pos >> lowres + 1;
//     int emu = 0, src_x, src_y, sx, sy;
//     ptrdiff_t offset;
//     const uint8_t *ptr;
// 
//     if (s->quarter_sample) {
//         mx /= 2;
//         my /= 2;
//     }
// 
//     /* In case of 8X8, we construct a single chroma motion vector
//        with a special rounding */
//     mx = ff_h263_round_chroma(mx);
//     my = ff_h263_round_chroma(my);
// 
//     sx = mx & s_mask;
//     sy = my & s_mask;
//     src_x = s->mb_x * block_s + (mx >> lowres + 1);
//     src_y = s->mb_y * block_s + (my >> lowres + 1);
// 
//     offset = src_y * s->uvlinesize + src_x;
//     ptr = ref_picture[1] + offset;
//     if ((unsigned) src_x > FFMAX(h_edge_pos - (!!sx) - block_s, 0) ||
//         (unsigned) src_y > FFMAX(v_edge_pos - (!!sy) - block_s, 0)) {
//         s->vdsp.emulated_edge_mc(s->sc.edge_emu_buffer, ptr,
//                                  s->uvlinesize, s->uvlinesize,
//                                  9, 9,
//                                  src_x, src_y, h_edge_pos, v_edge_pos);
//         ptr = s->sc.edge_emu_buffer;
//         emu = 1;
//     }
//     sx = (sx << 2) >> lowres;
//     sy = (sy << 2) >> lowres;
//     pix_op[op_index](dest_cb, ptr, s->uvlinesize, block_s, sx, sy);
// 
//     ptr = ref_picture[2] + offset;
//     if (emu) {
//         s->vdsp.emulated_edge_mc(s->sc.edge_emu_buffer, ptr,
//                                  s->uvlinesize, s->uvlinesize,
//                                  9, 9,
//                                  src_x, src_y, h_edge_pos, v_edge_pos);
//         ptr = s->sc.edge_emu_buffer;
//     }
//     pix_op[op_index](dest_cr, ptr, s->uvlinesize, block_s, sx, sy);
// }

// the below code fragment can be found in:
// libavcodec/mpegvideo_dec.c
// static int lowest_referenced_row(MpegEncContext *s, int dir)
// {
//     int my_max = INT_MIN, my_min = INT_MAX, qpel_shift = !s->quarter_sample;
//     int off, mvs;
// 
//     if (s->picture_structure != PICT_FRAME || s->mcsel)
//         goto unhandled;
// 
//     switch (s->mv_type) {
//         case MV_TYPE_16X16:
//             mvs = 1;
//             break;
//         case MV_TYPE_16X8:
//             mvs = 2;
//             break;
//         case MV_TYPE_8X8:
//             mvs = 4;
//             break;
//         default:
//             goto unhandled;
//     }
// 
//     for (int i = 0; i < mvs; i++) {
//         int my = s->mv[dir][i][1];
//         my_max = FFMAX(my_max, my);
//         my_min = FFMIN(my_min, my);
//     }
// 
//     off = ((FFMAX(-my_min, my_max) << qpel_shift) + 63) >> 6;
// 
//     return av_clip(s->mb_y + off, 0, s->mb_height - 1);
// unhandled:
//     return s->mb_height - 1;
// }

// the below code fragment can be found in:
// libavcodec/cavs.c
// static inline void mc_part_std(AVSContext *h, int chroma_height, int delta,
//                                uint8_t *dest_y,
//                                uint8_t *dest_cb,
//                                uint8_t *dest_cr,
//                                int x_offset, int y_offset,
//                                qpel_mc_func *qpix_put,
//                                h264_chroma_mc_func chroma_put,
//                                qpel_mc_func *qpix_avg,
//                                h264_chroma_mc_func chroma_avg,
//                                cavs_vector *mv)
// {
//     qpel_mc_func *qpix_op =  qpix_put;
//     h264_chroma_mc_func chroma_op = chroma_put;
// 
//     dest_y   += x_offset * 2 + y_offset * h->l_stride * 2;
//     dest_cb  += x_offset     + y_offset * h->c_stride;
//     dest_cr  += x_offset     + y_offset * h->c_stride;
//     x_offset += 8 * h->mbx;
//     y_offset += 8 * h->mby;
// 
//     if (mv->ref >= 0) {
//         AVFrame *ref = h->DPB[mv->ref].f;
//         mc_dir_part(h, ref, chroma_height, delta, 0,
//                     dest_y, dest_cb, dest_cr, x_offset, y_offset,
//                     qpix_op, chroma_op, mv);
// 
//         qpix_op   = qpix_avg;
//         chroma_op = chroma_avg;
//     }
// 
//     if ((mv + MV_BWD_OFFS)->ref >= 0) {
//         AVFrame *ref = h->DPB[0].f;
//         mc_dir_part(h, ref, chroma_height, delta, 1,
//                     dest_y, dest_cb, dest_cr, x_offset, y_offset,
//                     qpix_op, chroma_op, mv + MV_BWD_OFFS);
//     }
// }

// the below code fragment can be found in:
// libavcodec/h264_mb.c
// static av_always_inline void mc_part_std(const H264Context *h, H264SliceContext *sl,
//                                          int n, int square,
//                                          int height, int delta,
//                                          uint8_t *dest_y, uint8_t *dest_cb,
//                                          uint8_t *dest_cr,
//                                          int x_offset, int y_offset,
//                                          const qpel_mc_func *qpix_put,
//                                          h264_chroma_mc_func chroma_put,
//                                          const qpel_mc_func *qpix_avg,
//                                          h264_chroma_mc_func chroma_avg,
//                                          int list0, int list1,
//                                          int pixel_shift, int chroma_idc)
// {
//     const qpel_mc_func *qpix_op   = qpix_put;
//     h264_chroma_mc_func chroma_op = chroma_put;
// 
//     dest_y += (2 * x_offset << pixel_shift) + 2 * y_offset * sl->mb_linesize;
//     if (chroma_idc == 3 /* yuv444 */) {
//         dest_cb += (2 * x_offset << pixel_shift) + 2 * y_offset * sl->mb_linesize;
//         dest_cr += (2 * x_offset << pixel_shift) + 2 * y_offset * sl->mb_linesize;
//     } else if (chroma_idc == 2 /* yuv422 */) {
//         dest_cb += (x_offset << pixel_shift) + 2 * y_offset * sl->mb_uvlinesize;
//         dest_cr += (x_offset << pixel_shift) + 2 * y_offset * sl->mb_uvlinesize;
//     } else { /* yuv420 */
//         dest_cb += (x_offset << pixel_shift) + y_offset * sl->mb_uvlinesize;
//         dest_cr += (x_offset << pixel_shift) + y_offset * sl->mb_uvlinesize;
//     }
//     x_offset += 8 * sl->mb_x;
//     y_offset += 8 * (sl->mb_y >> MB_FIELD(sl));
// 
//     if (list0) {
//         H264Ref *ref = &sl->ref_list[0][sl->ref_cache[0][scan8[n]]];
//         mc_dir_part(h, sl, ref, n, square, height, delta, 0,
//                     dest_y, dest_cb, dest_cr, x_offset, y_offset,
//                     qpix_op, chroma_op, pixel_shift, chroma_idc);
// 
//         qpix_op   = qpix_avg;
//         chroma_op = chroma_avg;
//     }
// 
//     if (list1) {
//         H264Ref *ref = &sl->ref_list[1][sl->ref_cache[1][scan8[n]]];
//         mc_dir_part(h, sl, ref, n, square, height, delta, 1,
//                     dest_y, dest_cb, dest_cr, x_offset, y_offset,
//                     qpix_op, chroma_op, pixel_shift, chroma_idc);
//     }
// }

