// Here are some relevant code fragments from other files of the repo:

// the below code fragment can be found in:
// code/AssetLib/LWS/LWSLoader.cpp
void LWSImporter::BuildGraph(aiNode *nd, LWS::NodeDesc &src, std::vector<AttachmentInfo> &attach,
        BatchLoader &batch,
        aiCamera **&camOut,
        aiLight **&lightOut,
        std::vector<aiNodeAnim *> &animOut) {
    // Setup a very cryptic name for the node, we want the user to be happy
    SetupNodeName(nd, src);
    aiNode *ndAnim = nd;

    // If the node is an object
    if (src.type == LWS::NodeDesc::OBJECT) {

        // If the object is from an external file, get it
        aiScene *obj = nullptr;
        if (src.path.length()) {
            obj = batch.GetImport(src.id);
            if (!obj) {
                ASSIMP_LOG_ERROR("LWS: Failed to read external file ", src.path);
            } else {
                if (obj->mRootNode->mNumChildren == 1) {

                    //If the pivot is not set for this layer, get it from the external object
                    if (!src.isPivotSet) {
                        src.pivotPos.x = +obj->mRootNode->mTransformation.a4;
                        src.pivotPos.y = +obj->mRootNode->mTransformation.b4;
                        src.pivotPos.z = -obj->mRootNode->mTransformation.c4; //The sign is the RH to LH back conversion
                    }

                    //Remove first node from obj (the old pivot), reset transform of second node (the mesh node)
                    aiNode *newRootNode = obj->mRootNode->mChildren[0];
                    obj->mRootNode->mChildren[0] = nullptr;
                    delete obj->mRootNode;

                    obj->mRootNode = newRootNode;
                    obj->mRootNode->mTransformation.a4 = 0.0;
                    obj->mRootNode->mTransformation.b4 = 0.0;
                    obj->mRootNode->mTransformation.c4 = 0.0;
                }
            }
        }

        //Setup the pivot node (also the animation node), the one we received
        nd->mName = std::string("Pivot:") + nd->mName.data;
        ndAnim = nd;

        //Add the attachment node to it
        nd->mNumChildren = 1;
        nd->mChildren = new aiNode *[1];
        nd->mChildren[0] = new aiNode();
        nd->mChildren[0]->mParent = nd;
        nd->mChildren[0]->mTransformation.a4 = -src.pivotPos.x;
        nd->mChildren[0]->mTransformation.b4 = -src.pivotPos.y;
        nd->mChildren[0]->mTransformation.c4 = -src.pivotPos.z;
        SetupNodeName(nd->mChildren[0], src);

        //Update the attachment node
        nd = nd->mChildren[0];

        //Push attachment, if the object came from an external file
        if (obj) {
            attach.push_back(AttachmentInfo(obj, nd));
        }
    }

    // If object is a light source - setup a corresponding ai structure
    else if (src.type == LWS::NodeDesc::LIGHT) {
        aiLight *lit = *lightOut++ = new aiLight();

        // compute final light color
        lit->mColorDiffuse = lit->mColorSpecular = src.lightColor * src.lightIntensity;

        // name to attach light to node -> unique due to LWs indexing system
        lit->mName = nd->mName;

        // determine light type and setup additional members
        if (src.lightType == 2) { /* spot light */

            lit->mType = aiLightSource_SPOT;
            lit->mAngleInnerCone = (float)AI_DEG_TO_RAD(src.lightConeAngle);
            lit->mAngleOuterCone = lit->mAngleInnerCone + (float)AI_DEG_TO_RAD(src.lightEdgeAngle);

        } else if (src.lightType == 1) { /* directional light source */
            lit->mType = aiLightSource_DIRECTIONAL;
        } else {
            lit->mType = aiLightSource_POINT;
        }

        // fixme: no proper handling of light falloffs yet
        if (src.lightFalloffType == 1) {
            lit->mAttenuationConstant = 1.f;
        } else if (src.lightFalloffType == 2) {
            lit->mAttenuationLinear = 1.f;
        } else {
            lit->mAttenuationQuadratic = 1.f;
        }
    } else if (src.type == LWS::NodeDesc::CAMERA) { // If object is a camera - setup a corresponding ai structure
        aiCamera *cam = *camOut++ = new aiCamera();

        // name to attach cam to node -> unique due to LWs indexing system
        cam->mName = nd->mName;
    }

    // Get the node transformation from the LWO key
    LWO::AnimResolver resolver(src.channels, fps);
    resolver.ExtractBindPose(ndAnim->mTransformation);

    // .. and construct animation channels
    aiNodeAnim *anim = nullptr;

    if (first != last) {
        resolver.SetAnimationRange(first, last);
        resolver.ExtractAnimChannel(&anim, AI_LWO_ANIM_FLAG_SAMPLE_ANIMS | AI_LWO_ANIM_FLAG_START_AT_ZERO);
        if (anim) {
            anim->mNodeName = ndAnim->mName;
            animOut.push_back(anim);
        }
    }

    // Add children
    if (!src.children.empty()) {
        nd->mChildren = new aiNode *[src.children.size()];
        for (std::list<LWS::NodeDesc *>::iterator it = src.children.begin(); it != src.children.end(); ++it) {
            aiNode *ndd = nd->mChildren[nd->mNumChildren++] = new aiNode();
            ndd->mParent = nd;

            BuildGraph(ndd, **it, attach, batch, camOut, lightOut, animOut);
        }
    }
}

// the below code fragment can be found in:
// code/AssetLib/LWO/LWOLoader.cpp
void LWOImporter::InternReadFile(const std::string &pFile,
        aiScene *pScene,
        IOSystem *pIOHandler) {
    std::unique_ptr<IOStream> file(pIOHandler->Open(pFile, "rb"));

    // Check whether we can read from the file
    if (file.get() == nullptr) {
        throw DeadlyImportError("Failed to open LWO file ", pFile, ".");
    }

    if ((this->fileSize = (unsigned int)file->FileSize()) < 12) {
        throw DeadlyImportError("LWO: The file is too small to contain the IFF header");
    }

    // Allocate storage and copy the contents of the file to a memory buffer
    std::vector<uint8_t> mBuffer(fileSize);
    file->Read(&mBuffer[0], 1, fileSize);
    mScene = pScene;

    // Determine the type of the file
    uint32_t fileType;
    const char *sz = IFF::ReadHeader(&mBuffer[0], fileType);
    if (sz) {
        throw DeadlyImportError(sz);
    }

    mFileBuffer = &mBuffer[0] + 12;
    fileSize -= 12;

    // Initialize some members with their default values
    hasNamedLayer = false;

    // Create temporary storage on the stack but store pointers to it in the class
    // instance. Therefore everything will be destructed properly if an exception
    // is thrown and we needn't take care of that.
    LayerList _mLayers;
    SurfaceList _mSurfaces;
    TagList _mTags;
    TagMappingTable _mMapping;

    mLayers = &_mLayers;
    mTags = &_mTags;
    mMapping = &_mMapping;
    mSurfaces = &_mSurfaces;

    // Allocate a default layer (layer indices are 1-based from now)
    mLayers->push_back(Layer());
    mCurLayer = &mLayers->back();
    mCurLayer->mName = "<LWODefault>";
    mCurLayer->mIndex = (uint16_t) -1;

    // old lightwave file format (prior to v6)
    if (AI_LWO_FOURCC_LWOB == fileType) {
        ASSIMP_LOG_INFO("LWO file format: LWOB (<= LightWave 5.5)");

        mIsLWO2 = false;
        mIsLXOB = false;
        LoadLWOBFile();
    } else if (AI_LWO_FOURCC_LWO2 == fileType) {
        // New lightwave format
        mIsLXOB = false;
        ASSIMP_LOG_INFO("LWO file format: LWO2 (>= LightWave 6)");
    } else if (AI_LWO_FOURCC_LXOB == fileType) {
        // MODO file format
        mIsLXOB = true;
        ASSIMP_LOG_INFO("LWO file format: LXOB (Modo)");
    }
    else {
        char szBuff[5];
        szBuff[0] = (char)(fileType >> 24u);
        szBuff[1] = (char)(fileType >> 16u);
        szBuff[2] = (char)(fileType >> 8u);
        szBuff[3] = (char)(fileType);
        szBuff[4] = '\0';
        throw DeadlyImportError("Unknown LWO sub format: ", szBuff);
    }

    if (AI_LWO_FOURCC_LWOB != fileType) {
        mIsLWO2 = true;
        LoadLWO2File();

        // The newer lightwave format allows the user to configure the
        // loader that just one layer is used. If this is the case
        // we need to check now whether the requested layer has been found.
        if (UINT_MAX != configLayerIndex) {
            unsigned int layerCount = 0;
            for (std::list<LWO::Layer>::iterator itLayers = mLayers->begin(); itLayers != mLayers->end(); ++itLayers)
                if (!itLayers->skip)
                    layerCount++;
            if (layerCount != 2)
                throw DeadlyImportError("LWO2: The requested layer was not found");
        }

        if (configLayerName.length() && !hasNamedLayer) {
            throw DeadlyImportError("LWO2: Unable to find the requested layer: ", configLayerName);
        }
    }

    // now, as we have loaded all data, we can resolve cross-referenced tags and clips
    ResolveTags();
    ResolveClips();

    // now process all layers and build meshes and nodes
    std::vector<aiMesh *> apcMeshes;
    std::map<uint16_t, aiNode *> apcNodes;

    apcMeshes.reserve(mLayers->size() * std::min(((unsigned int)mSurfaces->size() / 2u), 1u));

    unsigned int iDefaultSurface = UINT_MAX; // index of the default surface
    for (LWO::Layer &layer : *mLayers) {
        if (layer.skip)
            continue;

        // I don't know whether there could be dummy layers, but it would be possible
        const unsigned int meshStart = (unsigned int)apcMeshes.size();
        if (!layer.mFaces.empty() && !layer.mTempPoints.empty()) {

            // now sort all faces by the surfaces assigned to them
            std::vector<SortedRep> pSorted(mSurfaces->size() + 1);

            unsigned int i = 0;
            for (FaceList::iterator it = layer.mFaces.begin(), end = layer.mFaces.end(); it != end; ++it, ++i) {
                // Check whether we support this face's type
                if ((*it).type != AI_LWO_FACE && (*it).type != AI_LWO_PTCH &&
                        (*it).type != AI_LWO_BONE && (*it).type != AI_LWO_SUBD) {
                    continue;
                }

                unsigned int idx = (*it).surfaceIndex;
                if (idx >= mTags->size()) {
                    ASSIMP_LOG_WARN("LWO: Invalid face surface index");
                    idx = UINT_MAX;
                }
                if (UINT_MAX == idx || UINT_MAX == (idx = _mMapping[idx])) {
                    if (UINT_MAX == iDefaultSurface) {
                        iDefaultSurface = (unsigned int)mSurfaces->size();
                        mSurfaces->push_back(LWO::Surface());
                        LWO::Surface &surf = mSurfaces->back();
                        surf.mColor.r = surf.mColor.g = surf.mColor.b = 0.6f;
                        surf.mName = "LWODefaultSurface";
                    }
                    idx = iDefaultSurface;
                }
                pSorted[idx].push_back(i);
            }
            if (UINT_MAX == iDefaultSurface) {
                pSorted.erase(pSorted.end() - 1);
            }
            for (unsigned int p = 0, j = 0; j < mSurfaces->size(); ++j) {
                SortedRep &sorted = pSorted[j];
                if (sorted.empty())
                    continue;

                // generate the mesh
                aiMesh *mesh = new aiMesh();
                apcMeshes.push_back(mesh);
                mesh->mNumFaces = (unsigned int)sorted.size();

                // count the number of vertices
                SortedRep::const_iterator it = sorted.begin(), end = sorted.end();
                for (; it != end; ++it) {
                    mesh->mNumVertices += layer.mFaces[*it].mNumIndices;
                }

                aiVector3D *nrm = nullptr, *pv = mesh->mVertices = new aiVector3D[mesh->mNumVertices];
                aiFace *pf = mesh->mFaces = new aiFace[mesh->mNumFaces];
                mesh->mMaterialIndex = j;

                // find out which vertex color channels and which texture coordinate
                // channels are really required by the material attached to this mesh
                unsigned int vUVChannelIndices[AI_MAX_NUMBER_OF_TEXTURECOORDS];
                unsigned int vVColorIndices[AI_MAX_NUMBER_OF_COLOR_SETS];

#ifdef ASSIMP_BUILD_DEBUG
                for (unsigned int mui = 0; mui < AI_MAX_NUMBER_OF_TEXTURECOORDS; ++mui) {
                    vUVChannelIndices[mui] = UINT_MAX;
                }
                for (unsigned int mui = 0; mui < AI_MAX_NUMBER_OF_COLOR_SETS; ++mui) {
                    vVColorIndices[mui] = UINT_MAX;
                }
#endif

                FindUVChannels(_mSurfaces[j], sorted, layer, vUVChannelIndices);
                FindVCChannels(_mSurfaces[j], sorted, layer, vVColorIndices);

                // allocate storage for UV and CV channels
                aiVector3D *pvUV[AI_MAX_NUMBER_OF_TEXTURECOORDS];
                for (unsigned int mui = 0; mui < AI_MAX_NUMBER_OF_TEXTURECOORDS; ++mui) {
                    if (UINT_MAX == vUVChannelIndices[mui]) {
                        break;
                    }

                    pvUV[mui] = mesh->mTextureCoords[mui] = new aiVector3D[mesh->mNumVertices];

                    // LightWave doesn't support more than 2 UV components (?)
                    mesh->mNumUVComponents[0] = 2;
                }

                if (layer.mNormals.name.length()) {
                    nrm = mesh->mNormals = new aiVector3D[mesh->mNumVertices];
                }

                aiColor4D *pvVC[AI_MAX_NUMBER_OF_COLOR_SETS];
                for (unsigned int mui = 0; mui < AI_MAX_NUMBER_OF_COLOR_SETS; ++mui) {
                    if (UINT_MAX == vVColorIndices[mui]) {
                        break;
                    }
                    pvVC[mui] = mesh->mColors[mui] = new aiColor4D[mesh->mNumVertices];
                }

                // we would not need this extra array, but the code is much cleaner if we use it
                std::vector<unsigned int> &smoothingGroups = layer.mPointReferrers;
                smoothingGroups.erase(smoothingGroups.begin(), smoothingGroups.end());
                smoothingGroups.resize(mesh->mNumFaces, 0);

                // now convert all faces
                unsigned int vert = 0;
                std::vector<unsigned int>::iterator outIt = smoothingGroups.begin();
                for (it = sorted.begin(); it != end; ++it, ++outIt) {
                    const LWO::Face &face = layer.mFaces[*it];
                    *outIt = face.smoothGroup;

                    // copy all vertices
                    for (unsigned int q = 0; q < face.mNumIndices; ++q, ++vert) {
                        unsigned int idx = face.mIndices[q];
                        *pv++ = layer.mTempPoints[idx] /*- layer.mPivot*/;

                        // process UV coordinates
                        for (unsigned int w = 0; w < AI_MAX_NUMBER_OF_TEXTURECOORDS; ++w) {
                            if (UINT_MAX == vUVChannelIndices[w]) {
                                break;
                            }
                            aiVector3D *&pp = pvUV[w];
                            const aiVector2D &src = ((aiVector2D *)&layer.mUVChannels[vUVChannelIndices[w]].rawData[0])[idx];
                            pp->x = src.x;
                            pp->y = src.y;
                            pp++;
                        }

                        // process normals (MODO extension)
                        if (nrm) {
                            *nrm = ((aiVector3D *)&layer.mNormals.rawData[0])[idx];
                            nrm->z *= -1.f;
                            ++nrm;
                        }

                        // process vertex colors
                        for (unsigned int w = 0; w < AI_MAX_NUMBER_OF_COLOR_SETS; ++w) {
                            if (UINT_MAX == vVColorIndices[w]) {
                                break;
                            }
                            *pvVC[w] = ((aiColor4D *)&layer.mVColorChannels[vVColorIndices[w]].rawData[0])[idx];

                            // If a RGB color map is explicitly requested delete the
                            // alpha channel - it could theoretically be != 1.
                            if (_mSurfaces[j].mVCMapType == AI_LWO_RGB)
                                pvVC[w]->a = 1.f;

                            pvVC[w]++;
                        }

#if 0
                        // process vertex weights. We can't properly reconstruct the whole skeleton for now,
                        // but we can create dummy bones for all weight channels which we have.
                        for (unsigned int w = 0; w < layer.mWeightChannels.size();++w)
                        {
                        }
#endif

                        face.mIndices[q] = vert;
                    }
                    pf->mIndices = face.mIndices;
                    pf->mNumIndices = face.mNumIndices;
                    unsigned int **facePtr = (unsigned int **)&face.mIndices;
                    *facePtr = nullptr; // HACK: make sure it won't be deleted
                    pf++;
                }

                if (!mesh->mNormals) {
                    // Compute normal vectors for the mesh - we can't use our GenSmoothNormal-
                    // Step here since it wouldn't handle smoothing groups correctly for LWO.
                    // So we use a separate implementation.
                    ComputeNormals(mesh, smoothingGroups, _mSurfaces[j]);
                } else {
                    ASSIMP_LOG_VERBOSE_DEBUG("LWO2: No need to compute normals, they're already there");
                }
                ++p;
            }
        }

        // Generate nodes to render the mesh. Store the source layer in the mParent member of the nodes
        unsigned int num = static_cast<unsigned int>(apcMeshes.size() - meshStart);
        if (layer.mName != "<LWODefault>" || num > 0) {
            aiNode *pcNode = new aiNode();
            pcNode->mName.Set(layer.mName);
            pcNode->mParent = (aiNode *)&layer;
            pcNode->mNumMeshes = num;

            if (pcNode->mNumMeshes) {
                pcNode->mMeshes = new unsigned int[pcNode->mNumMeshes];
                for (unsigned int p = 0; p < pcNode->mNumMeshes; ++p)
                    pcNode->mMeshes[p] = p + meshStart;
            }
            apcNodes[layer.mIndex] = pcNode;
        }
    }

    if (apcNodes.empty() || apcMeshes.empty())
        throw DeadlyImportError("LWO: No meshes loaded");

    // The RemoveRedundantMaterials step will clean this up later
    pScene->mMaterials = new aiMaterial *[pScene->mNumMaterials = (unsigned int)mSurfaces->size()];
    for (unsigned int mat = 0; mat < pScene->mNumMaterials; ++mat) {
        aiMaterial *pcMat = new aiMaterial();
        pScene->mMaterials[mat] = pcMat;
        ConvertMaterial((*mSurfaces)[mat], pcMat);
    }

    // copy the meshes to the output structure
    pScene->mMeshes = new aiMesh *[pScene->mNumMeshes = (unsigned int)apcMeshes.size()];
    ::memcpy(pScene->mMeshes, &apcMeshes[0], pScene->mNumMeshes * sizeof(void *));

    // generate the final node graph
    GenerateNodeGraph(apcNodes);
}

// the below code fragment can be found in:
// code/AssetLib/Irr/IRRLoader.cpp
void IRRImporter::InternReadFile(const std::string &pFile, aiScene *pScene, IOSystem *pIOHandler) {
	std::unique_ptr<IOStream> file(pIOHandler->Open(pFile));

	// Check whether we can read from the file
	if (file.get() == nullptr) {
        throw DeadlyImportError("Failed to open IRR file ", pFile);
	}

	// Construct the irrXML parser
	XmlParser st;
    if (!st.parse( file.get() )) {
        throw DeadlyImportError("XML parse error while loading IRR file ", pFile);
    }
    pugi::xml_node rootElement = st.getRootNode();

	// The root node of the scene
	Node *root = new Node(Node::DUMMY);
	root->parent = nullptr;
	root->name = "<IRRSceneRoot>";

	// Current node parent
	Node *curParent = root;

	// Scene-graph node we're currently working on
	Node *curNode = nullptr;

	// List of output cameras
	std::vector<aiCamera *> cameras;

	// List of output lights
	std::vector<aiLight *> lights;

	// Batch loader used to load external models
	BatchLoader batch(pIOHandler);
	//  batch.SetBasePath(pFile);

	cameras.reserve(5);
	lights.reserve(5);

	bool inMaterials = false, inAnimator = false;
	unsigned int guessedAnimCnt = 0, guessedMeshCnt = 0, guessedMatCnt = 0;

	// Parse the XML file

	//while (reader->read())  {
	for (pugi::xml_node child : rootElement.children())
		switch (child.type()) {
			case pugi::node_element:
				if (!ASSIMP_stricmp(child.name(), "node")) {
					// ***********************************************************************
					/*  What we're going to do with the node depends
                     *  on its type:
                     *
                     *  "mesh" - Load a mesh from an external file
                     *  "cube" - Generate a cube
                     *  "skybox" - Generate a skybox
                     *  "light" - A light source
                     *  "sphere" - Generate a sphere mesh
                     *  "animatedMesh" - Load an animated mesh from an external file
                     *    and join its animation channels with ours.
                     *  "empty" - A dummy node
                     *  "camera" - A camera
                     *  "terrain" - a terrain node (data comes from a heightmap)
                     *  "billboard", ""
                     *
                     *  Each of these nodes can be animated and all can have multiple
                     *  materials assigned (except lights, cameras and dummies, of course).
                     */
					// ***********************************************************************
					//const char *sz = reader->getAttributeValueSafe("type");
					pugi::xml_attribute attrib = child.attribute("type");
					Node *nd;
					if (!ASSIMP_stricmp(attrib.name(), "mesh") || !ASSIMP_stricmp(attrib.name(), "octTree")) {
						// OctTree's and meshes are treated equally
						nd = new Node(Node::MESH);
					} else if (!ASSIMP_stricmp(attrib.name(), "cube")) {
						nd = new Node(Node::CUBE);
						++guessedMeshCnt;
					} else if (!ASSIMP_stricmp(attrib.name(), "skybox")) {
						nd = new Node(Node::SKYBOX);
						guessedMeshCnt += 6;
					} else if (!ASSIMP_stricmp(attrib.name(), "camera")) {
						nd = new Node(Node::CAMERA);

						// Setup a temporary name for the camera
						aiCamera *cam = new aiCamera();
						cam->mName.Set(nd->name);
						cameras.push_back(cam);
					} else if (!ASSIMP_stricmp(attrib.name(), "light")) {
						nd = new Node(Node::LIGHT);

						// Setup a temporary name for the light
						aiLight *cam = new aiLight();
						cam->mName.Set(nd->name);
						lights.push_back(cam);
					} else if (!ASSIMP_stricmp(attrib.name(), "sphere")) {
						nd = new Node(Node::SPHERE);
						++guessedMeshCnt;
					} else if (!ASSIMP_stricmp(attrib.name(), "animatedMesh")) {
						nd = new Node(Node::ANIMMESH);
					} else if (!ASSIMP_stricmp(attrib.name(), "empty")) {
						nd = new Node(Node::DUMMY);
					} else if (!ASSIMP_stricmp(attrib.name(), "terrain")) {
						nd = new Node(Node::TERRAIN);
					} else if (!ASSIMP_stricmp(attrib.name(), "billBoard")) {
						// We don't support billboards, so ignore them
						ASSIMP_LOG_ERROR("IRR: Billboards are not supported by Assimp");
						nd = new Node(Node::DUMMY);
					} else {
						ASSIMP_LOG_WARN("IRR: Found unknown node: ", attrib.name());

						/*  We skip the contents of nodes we don't know.
                         *  We parse the transformation and all animators
                         *  and skip the rest.
                         */
						nd = new Node(Node::DUMMY);
					}

					/* Attach the newly created node to the scene-graph
                     */
					curNode = nd;
					nd->parent = curParent;
					curParent->children.push_back(nd);
				} else if (!ASSIMP_stricmp(child.name(), "materials")) {
					inMaterials = true;
				} else if (!ASSIMP_stricmp(child.name(), "animators")) {
					inAnimator = true;
				} else if (!ASSIMP_stricmp(child.name(), "attributes")) {
					//  We should have a valid node here
					//  FIX: no ... the scene root node is also contained in an attributes block
					if (!curNode) {
						continue;
					}

					Animator *curAnim = nullptr;

					// Materials can occur for nearly any type of node
					if (inMaterials && curNode->type != Node::DUMMY) {
						//  This is a material description - parse it!
						curNode->materials.push_back(std::pair<aiMaterial *, unsigned int>());
						std::pair<aiMaterial *, unsigned int> &p = curNode->materials.back();

						p.first = ParseMaterial(p.second);
						++guessedMatCnt;
						continue;
					} else if (inAnimator) {
						//  This is an animation path - add a new animator
						//  to the list.
						curNode->animators.push_back(Animator());
						curAnim = &curNode->animators.back();

						++guessedAnimCnt;
					}

					/*  Parse all elements in the attributes block
                     *  and process them.
                     */
					//					while (reader->read()) {
					for (pugi::xml_node attrib : child.children()) {
						if (attrib.type() == pugi::node_element) {
							//if (reader->getNodeType() == EXN_ELEMENT) {
							//if (!ASSIMP_stricmp(reader->getNodeName(), "vector3d")) {
							if (!ASSIMP_stricmp(attrib.name(), "vector3d")) {
								VectorProperty prop;
								ReadVectorProperty(prop);

								if (inAnimator) {
									if (curAnim->type == Animator::ROTATION && prop.name == "Rotation") {
										// We store the rotation euler angles in 'direction'
										curAnim->direction = prop.value;
									} else if (curAnim->type == Animator::FOLLOW_SPLINE) {
										// Check whether the vector follows the PointN naming scheme,
										// here N is the ONE-based index of the point
										if (prop.name.length() >= 6 && prop.name.substr(0, 5) == "Point") {
											// Add a new key to the list
											curAnim->splineKeys.push_back(aiVectorKey());
											aiVectorKey &key = curAnim->splineKeys.back();

											// and parse its properties
											key.mValue = prop.value;
											key.mTime = strtoul10(&prop.name[5]);
										}
									} else if (curAnim->type == Animator::FLY_CIRCLE) {
										if (prop.name == "Center") {
											curAnim->circleCenter = prop.value;
										} else if (prop.name == "Direction") {
											curAnim->direction = prop.value;

											// From Irrlicht's source - a workaround for backward compatibility with Irrlicht 1.1
											if (curAnim->direction == aiVector3D()) {
												curAnim->direction = aiVector3D(0.f, 1.f, 0.f);
											} else
												curAnim->direction.Normalize();
										}
									} else if (curAnim->type == Animator::FLY_STRAIGHT) {
										if (prop.name == "Start") {
											// We reuse the field here
											curAnim->circleCenter = prop.value;
										} else if (prop.name == "End") {
											// We reuse the field here
											curAnim->direction = prop.value;
										}
									}
								} else {
									if (prop.name == "Position") {
										curNode->position = prop.value;
									} else if (prop.name == "Rotation") {
										curNode->rotation = prop.value;
									} else if (prop.name == "Scale") {
										curNode->scaling = prop.value;
									} else if (Node::CAMERA == curNode->type) {
										aiCamera *cam = cameras.back();
										if (prop.name == "Target") {
											cam->mLookAt = prop.value;
										} else if (prop.name == "UpVector") {
											cam->mUp = prop.value;
										}
									}
								}
								//} else if (!ASSIMP_stricmp(reader->getNodeName(), "bool")) {
							} else if (!ASSIMP_stricmp(attrib.name(), "bool")) {
								BoolProperty prop;
								ReadBoolProperty(prop);

								if (inAnimator && curAnim->type == Animator::FLY_CIRCLE && prop.name == "Loop") {
									curAnim->loop = prop.value;
								}
								//} else if (!ASSIMP_stricmp(reader->getNodeName(), "float")) {
							} else if (!ASSIMP_stricmp(attrib.name(), "float")) {
								FloatProperty prop;
								ReadFloatProperty(prop);

								if (inAnimator) {
									// The speed property exists for several animators
									if (prop.name == "Speed") {
										curAnim->speed = prop.value;
									} else if (curAnim->type == Animator::FLY_CIRCLE && prop.name == "Radius") {
										curAnim->circleRadius = prop.value;
									} else if (curAnim->type == Animator::FOLLOW_SPLINE && prop.name == "Tightness") {
										curAnim->tightness = prop.value;
									}
								} else {
									if (prop.name == "FramesPerSecond" && Node::ANIMMESH == curNode->type) {
										curNode->framesPerSecond = prop.value;
									} else if (Node::CAMERA == curNode->type) {
										/*  This is the vertical, not the horizontal FOV.
                                    *  We need to compute the right FOV from the
                                    *  screen aspect which we don't know yet.
                                    */
										if (prop.name == "Fovy") {
											cameras.back()->mHorizontalFOV = prop.value;
										} else if (prop.name == "Aspect") {
											cameras.back()->mAspect = prop.value;
										} else if (prop.name == "ZNear") {
											cameras.back()->mClipPlaneNear = prop.value;
										} else if (prop.name == "ZFar") {
											cameras.back()->mClipPlaneFar = prop.value;
										}
									} else if (Node::LIGHT == curNode->type) {
										/*  Additional light information
                                     */
										if (prop.name == "Attenuation") {
											lights.back()->mAttenuationLinear = prop.value;
										} else if (prop.name == "OuterCone") {
											lights.back()->mAngleOuterCone = AI_DEG_TO_RAD(prop.value);
										} else if (prop.name == "InnerCone") {
											lights.back()->mAngleInnerCone = AI_DEG_TO_RAD(prop.value);
										}
									}
									// radius of the sphere to be generated -
									// or alternatively, size of the cube
									else if ((Node::SPHERE == curNode->type && prop.name == "Radius") || (Node::CUBE == curNode->type && prop.name == "Size")) {

										curNode->sphereRadius = prop.value;
									}
								}
								//} else if (!ASSIMP_stricmp(reader->getNodeName(), "int")) {
							} else if (!ASSIMP_stricmp(attrib.name(), "int")) {
								IntProperty prop;
								ReadIntProperty(prop);

								if (inAnimator) {
									if (curAnim->type == Animator::FLY_STRAIGHT && prop.name == "TimeForWay") {
										curAnim->timeForWay = prop.value;
									}
								} else {
									// sphere polygon numbers in each direction
									if (Node::SPHERE == curNode->type) {

										if (prop.name == "PolyCountX") {
											curNode->spherePolyCountX = prop.value;
										} else if (prop.name == "PolyCountY") {
											curNode->spherePolyCountY = prop.value;
										}
									}
								}
								//} else if (!ASSIMP_stricmp(reader->getNodeName(), "string") || !ASSIMP_stricmp(reader->getNodeName(), "enum")) {
							} else if (!ASSIMP_stricmp(attrib.name(), "string") || !ASSIMP_stricmp(attrib.name(), "enum")) {
								StringProperty prop;
								ReadStringProperty(prop);
								if (prop.value.length()) {
									if (prop.name == "Name") {
										curNode->name = prop.value;

										/*  If we're either a camera or a light source
                                     *  we need to update the name in the aiLight/
                                     *  aiCamera structure, too.
                                     */
										if (Node::CAMERA == curNode->type) {
											cameras.back()->mName.Set(prop.value);
										} else if (Node::LIGHT == curNode->type) {
											lights.back()->mName.Set(prop.value);
										}
									} else if (Node::LIGHT == curNode->type && "LightType" == prop.name) {
										if (prop.value == "Spot")
											lights.back()->mType = aiLightSource_SPOT;
										else if (prop.value == "Point")
											lights.back()->mType = aiLightSource_POINT;
										else if (prop.value == "Directional")
											lights.back()->mType = aiLightSource_DIRECTIONAL;
										else {
											// We won't pass the validation with aiLightSourceType_UNDEFINED,
											// so we remove the light and replace it with a silly dummy node
											delete lights.back();
											lights.pop_back();
											curNode->type = Node::DUMMY;

											ASSIMP_LOG_ERROR("Ignoring light of unknown type: ", prop.value);
										}
									} else if ((prop.name == "Mesh" && Node::MESH == curNode->type) ||
											   Node::ANIMMESH == curNode->type) {
    								/*  This is the file name of the mesh - either
                                     *  animated or not. We need to make sure we setup
                                     *  the correct post-processing settings here.
                                     */
										unsigned int pp = 0;
										BatchLoader::PropertyMap map;

										/* If the mesh is a static one remove all animations from the impor data
                                     */
										if (Node::ANIMMESH != curNode->type) {
											pp |= aiProcess_RemoveComponent;
											SetGenericProperty<int>(map.ints, AI_CONFIG_PP_RVC_FLAGS,
													aiComponent_ANIMATIONS | aiComponent_BONEWEIGHTS);
										}

										/*  TODO: maybe implement the protection against recursive
                                        *  loading calls directly in BatchLoader? The current
                                        *  implementation is not absolutely safe. A LWS and an IRR
                                        *  file referencing each other *could* cause the system to
                                        *  recurse forever.
                                        */

										const std::string extension = GetExtension(prop.value);
										if ("irr" == extension) {
											ASSIMP_LOG_ERROR("IRR: Can't load another IRR file recursively");
										} else {
											curNode->id = batch.AddLoadRequest(prop.value, pp, &map);
											curNode->meshPath = prop.value;
										}
									} else if (inAnimator && prop.name == "Type") {
										// type of the animator
										if (prop.value == "rotation") {
											curAnim->type = Animator::ROTATION;
										} else if (prop.value == "flyCircle") {
											curAnim->type = Animator::FLY_CIRCLE;
										} else if (prop.value == "flyStraight") {
											curAnim->type = Animator::FLY_CIRCLE;
										} else if (prop.value == "followSpline") {
											curAnim->type = Animator::FOLLOW_SPLINE;
										} else {
											ASSIMP_LOG_WARN("IRR: Ignoring unknown animator: ", prop.value);

											curAnim->type = Animator::UNKNOWN;
										}
									}
								}
							}
							//} else if (reader->getNodeType() == EXN_ELEMENT_END && !ASSIMP_stricmp(reader->getNodeName(), "attributes")) {
						} else if (attrib.type() == pugi::node_null && !ASSIMP_stricmp(attrib.name(), "attributes")) {
							break;
						}
					}
				}
				break;

				/*case EXN_ELEMENT_END:

				// If we reached the end of a node, we need to continue processing its parent
				if (!ASSIMP_stricmp(reader->getNodeName(), "node")) {
					if (!curNode) {
						// currently is no node set. We need to go
						// back in the node hierarchy
						if (!curParent) {
							curParent = root;
							ASSIMP_LOG_ERROR("IRR: Too many closing <node> elements");
						} else
							curParent = curParent->parent;
					} else
						curNode = nullptr;
				}
				// clear all flags
				else if (!ASSIMP_stricmp(reader->getNodeName(), "materials")) {
					inMaterials = false;
				} else if (!ASSIMP_stricmp(reader->getNodeName(), "animators")) {
					inAnimator = false;
				}
				break;*/

			default:
				// GCC complains that not all enumeration values are handled
				break;
		}
	//}

	//  Now iterate through all cameras and compute their final (horizontal) FOV
	for (aiCamera *cam : cameras) {
		// screen aspect could be missing
		if (cam->mAspect) {
			cam->mHorizontalFOV *= cam->mAspect;
		} else {
			ASSIMP_LOG_WARN("IRR: Camera aspect is not given, can't compute horizontal FOV");
		}
	}

	batch.LoadAll();

	// Allocate a temporary scene data structure
	aiScene *tempScene = new aiScene();
	tempScene->mRootNode = new aiNode();
	tempScene->mRootNode->mName.Set("<IRRRoot>");

	// Copy the cameras to the output array
	if (!cameras.empty()) {
		tempScene->mNumCameras = (unsigned int)cameras.size();
		tempScene->mCameras = new aiCamera *[tempScene->mNumCameras];
		::memcpy(tempScene->mCameras, &cameras[0], sizeof(void *) * tempScene->mNumCameras);
	}

	// Copy the light sources to the output array
	if (!lights.empty()) {
		tempScene->mNumLights = (unsigned int)lights.size();
		tempScene->mLights = new aiLight *[tempScene->mNumLights];
		::memcpy(tempScene->mLights, &lights[0], sizeof(void *) * tempScene->mNumLights);
	}

	// temporary data
	std::vector<aiNodeAnim *> anims;
	std::vector<aiMaterial *> materials;
	std::vector<AttachmentInfo> attach;
	std::vector<aiMesh *> meshes;

	// try to guess how much storage we'll need
	anims.reserve(guessedAnimCnt + (guessedAnimCnt >> 2));
	meshes.reserve(guessedMeshCnt + (guessedMeshCnt >> 2));
	materials.reserve(guessedMatCnt + (guessedMatCnt >> 2));

	// Now process our scene-graph recursively: generate final
	// meshes and generate animation channels for all nodes.
	unsigned int defMatIdx = UINT_MAX;
	GenerateGraph(root, tempScene->mRootNode, tempScene,
			batch, meshes, anims, attach, materials, defMatIdx);

	if (!anims.empty()) {
		tempScene->mNumAnimations = 1;
		tempScene->mAnimations = new aiAnimation *[tempScene->mNumAnimations];
		aiAnimation *an = tempScene->mAnimations[0] = new aiAnimation();

		// ***********************************************************
		// This is only the global animation channel of the scene.
		// If there are animated models, they will have separate
		// animation channels in the scene. To display IRR scenes
		// correctly, users will need to combine the global anim
		// channel with all the local animations they want to play
		// ***********************************************************
		an->mName.Set("Irr_GlobalAnimChannel");

		// copy all node animation channels to the global channel
		an->mNumChannels = (unsigned int)anims.size();
		an->mChannels = new aiNodeAnim *[an->mNumChannels];
		::memcpy(an->mChannels, &anims[0], sizeof(void *) * an->mNumChannels);
	}
	if (!meshes.empty()) {
		// copy all meshes to the temporary scene
		tempScene->mNumMeshes = (unsigned int)meshes.size();
		tempScene->mMeshes = new aiMesh *[tempScene->mNumMeshes];
		::memcpy(tempScene->mMeshes, &meshes[0], tempScene->mNumMeshes * sizeof(void *));
	}

	// Copy all materials to the output array
	if (!materials.empty()) {
		tempScene->mNumMaterials = (unsigned int)materials.size();
		tempScene->mMaterials = new aiMaterial *[tempScene->mNumMaterials];
		::memcpy(tempScene->mMaterials, &materials[0], sizeof(void *) * tempScene->mNumMaterials);
	}

	//  Now merge all sub scenes and attach them to the correct
	//  attachment points in the scenegraph.
	SceneCombiner::MergeScenes(&pScene, tempScene, attach,
			AI_INT_MERGE_SCENE_GEN_UNIQUE_NAMES | (!configSpeedFlag ? (
																			  AI_INT_MERGE_SCENE_GEN_UNIQUE_NAMES_IF_NECESSARY | AI_INT_MERGE_SCENE_GEN_UNIQUE_MATNAMES) :
																	  0));

	// If we have no meshes | no materials now set the INCOMPLETE
	// scene flag. This is necessary if we failed to load all
	// models from external files
	if (!pScene->mNumMeshes || !pScene->mNumMaterials) {
		ASSIMP_LOG_WARN("IRR: No meshes loaded, setting AI_SCENE_FLAGS_INCOMPLETE");
		pScene->mFlags |= AI_SCENE_FLAGS_INCOMPLETE;
	}

	// Finished ... everything destructs automatically and all
	// temporary scenes have already been deleted by MergeScenes()
	delete root;
}

// the below code fragment can be found in:
// code/AssetLib/MS3D/MS3DLoader.cpp
void MS3DImporter::InternReadFile( const std::string& pFile,
    aiScene* pScene, IOSystem* pIOHandler)
{

    auto file = pIOHandler->Open(pFile, "rb");
    if (!file)
        throw DeadlyImportError("MS3D: Could not open ", pFile);

    StreamReaderLE stream(file);

    // CanRead() should have done this already
    char head[10];
    int32_t version;

    mScene = pScene;


    // 1 ------------ read into temporary data structures mirroring the original file

    stream.CopyAndAdvance(head,10);
    stream >> version;
    if (strncmp(head,"MS3D000000",10)) {
        throw DeadlyImportError("Not a MS3D file, magic string MS3D000000 not found: ", pFile);
    }

    if (version != 4) {
        throw DeadlyImportError("MS3D: Unsupported file format version, 4 was expected");
    }

    uint16_t verts;
    stream >> verts;

    std::vector<TempVertex> vertices(verts);
    for (unsigned int i = 0; i < verts; ++i) {
        TempVertex& v = vertices[i];

        stream.IncPtr(1);
        ReadVector(stream,v.pos);
        v.bone_id[0] = stream.GetI1();
        v.ref_cnt = stream.GetI1();

        v.bone_id[1] = v.bone_id[2] = v.bone_id[3] = UINT_MAX;
        v.weights[1] = v.weights[2] = v.weights[3] = 0.f;
        v.weights[0] = 1.f;
    }

    uint16_t tris;
    stream >> tris;

    std::vector<TempTriangle> triangles(tris);
    for (unsigned int i = 0;i < tris; ++i) {
        TempTriangle& t = triangles[i];

        stream.IncPtr(2);
        for (unsigned int j = 0; j < 3; ++j) {
            t.indices[j] = stream.GetI2();
        }

        for (unsigned int j = 0; j < 3; ++j) {
            ReadVector(stream,t.normals[j]);
        }

        for (unsigned int j = 0; j < 3; ++j) {
            stream >> (float&)(t.uv[j].x); // see note in ReadColor()
        }
        for (unsigned int j = 0; j < 3; ++j) {
            stream >> (float&)(t.uv[j].y);
        }

        t.sg    = stream.GetI1();
        t.group = stream.GetI1();
    }

    uint16_t grp;
    stream >> grp;

    bool need_default = false;
    std::vector<TempGroup> groups(grp);
    for (unsigned int i = 0;i < grp; ++i) {
        TempGroup& t = groups[i];

        stream.IncPtr(1);
        stream.CopyAndAdvance(t.name,32);

        t.name[32] = '\0';
        uint16_t num;
        stream >> num;

        t.triangles.resize(num);
        for (unsigned int j = 0; j < num; ++j) {
            t.triangles[j] = stream.GetI2();
        }
        t.mat = stream.GetI1();
        if (t.mat == UINT_MAX) {
            need_default = true;
        }
    }

    uint16_t mat;
    stream >> mat;

    std::vector<TempMaterial> materials(mat);
    for (unsigned int j = 0;j < mat; ++j) {
        TempMaterial& t = materials[j];

        stream.CopyAndAdvance(t.name,32);
        t.name[32] = '\0';

        ReadColor(stream,t.ambient);
        ReadColor(stream,t.diffuse);
        ReadColor(stream,t.specular);
        ReadColor(stream,t.emissive);
        stream >> t.shininess  >> t.transparency;

        stream.IncPtr(1);

        stream.CopyAndAdvance(t.texture,128);
        t.texture[128] = '\0';

        stream.CopyAndAdvance(t.alphamap,128);
        t.alphamap[128] = '\0';
    }

    float animfps, currenttime;
    uint32_t totalframes;
    stream >> animfps >> currenttime >> totalframes;

    uint16_t joint;
    stream >> joint;

    std::vector<TempJoint> joints(joint);
    for(unsigned int ii = 0; ii < joint; ++ii) {
        TempJoint& j = joints[ii];

        stream.IncPtr(1);
        stream.CopyAndAdvance(j.name,32);
        j.name[32] = '\0';

        stream.CopyAndAdvance(j.parentName,32);
        j.parentName[32] = '\0';

        ReadVector(stream,j.rotation);
        ReadVector(stream,j.position);

        j.rotFrames.resize(stream.GetI2());
        j.posFrames.resize(stream.GetI2());

        for(unsigned int a = 0; a < j.rotFrames.size(); ++a) {
            TempKeyFrame& kf = j.rotFrames[a];
            stream >> kf.time;
            ReadVector(stream,kf.value);
        }
        for(unsigned int a = 0; a < j.posFrames.size(); ++a) {
            TempKeyFrame& kf = j.posFrames[a];
            stream >> kf.time;
            ReadVector(stream,kf.value);
        }
    }

    if(stream.GetRemainingSize() > 4) {
        uint32_t subversion;
        stream >> subversion;
        if (subversion == 1) {
            ReadComments<TempGroup>(stream,groups);
            ReadComments<TempMaterial>(stream,materials);
            ReadComments<TempJoint>(stream,joints);

            // model comment - print it for we have such a nice log.
            if (stream.GetI4()) {
                const size_t len = static_cast<size_t>(stream.GetI4());
                if (len > stream.GetRemainingSize()) {
                    throw DeadlyImportError("MS3D: Model comment is too long");
                }

                const std::string& s = std::string(reinterpret_cast<char*>(stream.GetPtr()),len);
                ASSIMP_LOG_DEBUG("MS3D: Model comment: ", s);
            }

            if(stream.GetRemainingSize() > 4 && inrange((stream >> subversion,subversion),1u,3u)) {
                for(unsigned int i = 0; i < verts; ++i) {
                    TempVertex& v = vertices[i];
                    v.weights[3]=1.f;
                    for(unsigned int n = 0; n < 3; v.weights[3]-=v.weights[n++]) {
                        v.bone_id[n+1] = stream.GetI1();
                        v.weights[n] = static_cast<float>(static_cast<unsigned int>(stream.GetI1()))/255.f;
                    }
                    stream.IncPtr((subversion-1)<<2u);
                }

                // even further extra data is not of interest for us, at least now now.
            }
        }
    }

    // 2 ------------ convert to proper aiXX data structures -----------------------------------

    if (need_default && materials.size()) {
        ASSIMP_LOG_WARN("MS3D: Found group with no material assigned, spawning default material");
        // if one of the groups has no material assigned, but there are other
        // groups with materials, a default material needs to be added (
        // scenepreprocessor adds a default material only if nummat==0).
        materials.push_back(TempMaterial());
        TempMaterial& m = materials.back();

        strcpy(m.name,"<MS3D_DefaultMat>");
        m.diffuse = aiColor4D(0.6f,0.6f,0.6f,1.0);
        m.transparency = 1.f;
        m.shininess = 0.f;

        // this is because these TempXXX struct's have no c'tors.
        m.texture[0] = m.alphamap[0] = '\0';

        for (unsigned int i = 0; i < groups.size(); ++i) {
            TempGroup& g = groups[i];
            if (g.mat == UINT_MAX) {
                g.mat = static_cast<unsigned int>(materials.size()-1);
            }
        }
    }

    // convert materials to our generic key-value dict-alike
    if (materials.size()) {
        pScene->mMaterials = new aiMaterial*[materials.size()];
        for (size_t i = 0; i < materials.size(); ++i) {

            aiMaterial* mo = new aiMaterial();
            pScene->mMaterials[pScene->mNumMaterials++] = mo;

            const TempMaterial& mi = materials[i];

            aiString tmp;
            if (0[mi.alphamap]) {
                tmp = aiString(mi.alphamap);
                mo->AddProperty(&tmp,AI_MATKEY_TEXTURE_OPACITY(0));
            }
            if (0[mi.texture]) {
                tmp = aiString(mi.texture);
                mo->AddProperty(&tmp,AI_MATKEY_TEXTURE_DIFFUSE(0));
            }
            if (0[mi.name]) {
                tmp = aiString(mi.name);
                mo->AddProperty(&tmp,AI_MATKEY_NAME);
            }

            mo->AddProperty(&mi.ambient,1,AI_MATKEY_COLOR_AMBIENT);
            mo->AddProperty(&mi.diffuse,1,AI_MATKEY_COLOR_DIFFUSE);
            mo->AddProperty(&mi.specular,1,AI_MATKEY_COLOR_SPECULAR);
            mo->AddProperty(&mi.emissive,1,AI_MATKEY_COLOR_EMISSIVE);

            mo->AddProperty(&mi.shininess,1,AI_MATKEY_SHININESS);
            mo->AddProperty(&mi.transparency,1,AI_MATKEY_OPACITY);

            const int sm = mi.shininess>0.f?aiShadingMode_Phong:aiShadingMode_Gouraud;
            mo->AddProperty(&sm,1,AI_MATKEY_SHADING_MODEL);
        }
    }

    // convert groups to meshes
    if (groups.empty()) {
        throw DeadlyImportError("MS3D: Didn't get any group records, file is malformed");
    }

    pScene->mMeshes = new aiMesh*[pScene->mNumMeshes=static_cast<unsigned int>(groups.size())]();
    for (unsigned int i = 0; i < pScene->mNumMeshes; ++i) {

        aiMesh* m = pScene->mMeshes[i] = new aiMesh();
        const TempGroup& g = groups[i];

        if (pScene->mNumMaterials && g.mat > pScene->mNumMaterials) {
            throw DeadlyImportError("MS3D: Encountered invalid material index, file is malformed");
        } // no error if no materials at all - scenepreprocessor adds one then

        m->mMaterialIndex  = g.mat;
        m->mPrimitiveTypes = aiPrimitiveType_TRIANGLE;

        m->mFaces = new aiFace[m->mNumFaces = static_cast<unsigned int>(g.triangles.size())];
        m->mNumVertices = m->mNumFaces*3;

        // storage for vertices - verbose format, as requested by the postprocessing pipeline
        m->mVertices = new aiVector3D[m->mNumVertices];
        m->mNormals  = new aiVector3D[m->mNumVertices];
        m->mTextureCoords[0] = new aiVector3D[m->mNumVertices];
        m->mNumUVComponents[0] = 2;

        typedef std::map<unsigned int,unsigned int> BoneSet;
        BoneSet mybones;

        for (unsigned int j = 0,n = 0; j < m->mNumFaces; ++j) {
            aiFace& f = m->mFaces[j];
            if (g.triangles[j]>triangles.size()) {
                throw DeadlyImportError("MS3D: Encountered invalid triangle index, file is malformed");
            }

            TempTriangle& t = triangles[g.triangles[j]];
            f.mIndices = new unsigned int[f.mNumIndices=3];

            for (unsigned int k = 0; k < 3; ++k,++n) {
                if (t.indices[k]>vertices.size()) {
                    throw DeadlyImportError("MS3D: Encountered invalid vertex index, file is malformed");
                }

                const TempVertex& v = vertices[t.indices[k]];
                for(unsigned int a = 0; a < 4; ++a) {
                    if (v.bone_id[a] != UINT_MAX) {
                        if (v.bone_id[a] >= joints.size()) {
                            throw DeadlyImportError("MS3D: Encountered invalid bone index, file is malformed");
                        }
                        if (mybones.find(v.bone_id[a]) == mybones.end()) {
                             mybones[v.bone_id[a]] = 1;
                        }
                        else ++mybones[v.bone_id[a]];
                    }
                }

                // collect vertex components
                m->mVertices[n] = v.pos;

                m->mNormals[n] = t.normals[k];
                m->mTextureCoords[0][n] = aiVector3D(t.uv[k].x,1.f-t.uv[k].y,0.0);
                f.mIndices[k] = n;
            }
        }

        // allocate storage for bones
        if(!mybones.empty()) {
            std::vector<unsigned int> bmap(joints.size());
            m->mBones = new aiBone*[mybones.size()]();
            for(BoneSet::const_iterator it = mybones.begin(); it != mybones.end(); ++it) {
                aiBone* const bn = m->mBones[m->mNumBones] = new aiBone();
                const TempJoint& jnt = joints[(*it).first];

                bn->mName.Set(jnt.name);
                bn->mWeights = new aiVertexWeight[(*it).second];

                bmap[(*it).first] = m->mNumBones++;
            }

            // .. and collect bone weights
            for (unsigned int j = 0,n = 0; j < m->mNumFaces; ++j) {
                TempTriangle& t = triangles[g.triangles[j]];

                for (unsigned int k = 0; k < 3; ++k,++n) {
                    const TempVertex& v = vertices[t.indices[k]];
                    for(unsigned int a = 0; a < 4; ++a) {
                        const unsigned int bone = v.bone_id[a];
                        if(bone==UINT_MAX){
                            continue;
                        }

                        aiBone* const outbone = m->mBones[bmap[bone]];
                        aiVertexWeight& outwght = outbone->mWeights[outbone->mNumWeights++];

                        outwght.mVertexId = n;
                        outwght.mWeight = v.weights[a];
                    }
                }
            }
        }
    }

    // ... add dummy nodes under a single root, each holding a reference to one
    // mesh. If we didn't do this, we'd lose the group name.
    aiNode* rt = pScene->mRootNode = new aiNode("<MS3DRoot>");

#ifdef ASSIMP_BUILD_MS3D_ONE_NODE_PER_MESH
    rt->mChildren = new aiNode*[rt->mNumChildren=pScene->mNumMeshes+(joints.size()?1:0)]();

    for (unsigned int i = 0; i < pScene->mNumMeshes; ++i) {
        aiNode* nd = rt->mChildren[i] = new aiNode();

        const TempGroup& g = groups[i];

        // we need to generate an unique name for all mesh nodes.
        // since we want to keep the group name, a prefix is
        // prepended.
        nd->mName = aiString("<MS3DMesh>_");
        nd->mName.Append(g.name);
        nd->mParent = rt;

        nd->mMeshes = new unsigned int[nd->mNumMeshes = 1];
        nd->mMeshes[0] = i;
    }
#else
    rt->mMeshes = new unsigned int[pScene->mNumMeshes];
    for (unsigned int i = 0; i < pScene->mNumMeshes; ++i) {
        rt->mMeshes[rt->mNumMeshes++] = i;
    }
#endif

    // convert animations as well
    if(joints.size()) {
#ifndef ASSIMP_BUILD_MS3D_ONE_NODE_PER_MESH
        rt->mChildren = new aiNode*[1]();
        rt->mNumChildren = 1;

        aiNode* jt = rt->mChildren[0] = new aiNode();
#else
        aiNode* jt = rt->mChildren[pScene->mNumMeshes] = new aiNode();
#endif
        jt->mParent = rt;
        CollectChildJoints(joints,jt);
        jt->mName.Set("<MS3DJointRoot>");

        pScene->mAnimations = new aiAnimation*[ pScene->mNumAnimations = 1 ];
        aiAnimation* const anim = pScene->mAnimations[0] = new aiAnimation();

        anim->mName.Set("<MS3DMasterAnim>");

        // carry the fps info to the user by scaling all times with it
        anim->mTicksPerSecond = animfps;

        // leave duration at its default, so ScenePreprocessor will fill an appropriate
        // value (the values taken from some MS3D files seem to be too unreliable
        // to pass the validation)
        // anim->mDuration = totalframes/animfps;

        anim->mChannels = new aiNodeAnim*[joints.size()]();
        for(std::vector<TempJoint>::const_iterator it = joints.begin(); it != joints.end(); ++it) {
            if ((*it).rotFrames.empty() && (*it).posFrames.empty()) {
                continue;
            }

            aiNodeAnim* nd = anim->mChannels[anim->mNumChannels++] = new aiNodeAnim();
            nd->mNodeName.Set((*it).name);

            if ((*it).rotFrames.size()) {
                nd->mRotationKeys = new aiQuatKey[(*it).rotFrames.size()];
                for(std::vector<TempKeyFrame>::const_iterator rot = (*it).rotFrames.begin(); rot != (*it).rotFrames.end(); ++rot) {
                    aiQuatKey& q = nd->mRotationKeys[nd->mNumRotationKeys++];

                    q.mTime = (*rot).time*animfps;
                    q.mValue = aiQuaternion(aiMatrix3x3(aiMatrix4x4().FromEulerAnglesXYZ((*it).rotation)*
                        aiMatrix4x4().FromEulerAnglesXYZ((*rot).value)));
                }
            }

            if ((*it).posFrames.size()) {
                nd->mPositionKeys = new aiVectorKey[(*it).posFrames.size()];

                aiQuatKey* qu = nd->mRotationKeys;
                for(std::vector<TempKeyFrame>::const_iterator pos = (*it).posFrames.begin(); pos != (*it).posFrames.end(); ++pos,++qu) {
                    aiVectorKey& v = nd->mPositionKeys[nd->mNumPositionKeys++];

                    v.mTime = (*pos).time*animfps;
                    v.mValue = (*it).position + (*pos).value;
                }
            }
        }
        // fixup to pass the validation if not a single animation channel is non-trivial
        if (!anim->mNumChannels) {
            anim->mChannels = nullptr;
        }
    }
}

// the below code fragment can be found in:
// code/AssetLib/Q3D/Q3DLoader.cpp
void Q3DImporter::InternReadFile(const std::string &pFile,
        aiScene *pScene, IOSystem *pIOHandler) {

    auto file = pIOHandler->Open(pFile, "rb");
    if (!file)
        throw DeadlyImportError("Quick3D: Could not open ", pFile);

    StreamReaderLE stream(file);

    // The header is 22 bytes large
    if (stream.GetRemainingSize() < 22)
        throw DeadlyImportError("File is either empty or corrupt: ", pFile);

    // Check the file's signature
    if (ASSIMP_strincmp((const char *)stream.GetPtr(), "quick3Do", 8) &&
            ASSIMP_strincmp((const char *)stream.GetPtr(), "quick3Ds", 8)) {
        throw DeadlyImportError("Not a Quick3D file. Signature string is: ", ai_str_toprintable((const char *)stream.GetPtr(), 8));
    }

    // Print the file format version
    ASSIMP_LOG_INFO("Quick3D File format version: ",
            std::string(&((const char *)stream.GetPtr())[8], 2));

    // ... an store it
    char major = ((const char *)stream.GetPtr())[8];
    char minor = ((const char *)stream.GetPtr())[9];

    stream.IncPtr(10);
    unsigned int numMeshes = (unsigned int)stream.GetI4();
    unsigned int numMats = (unsigned int)stream.GetI4();
    unsigned int numTextures = (unsigned int)stream.GetI4();

    std::vector<Material> materials;
    materials.reserve(numMats);

    std::vector<Mesh> meshes;
    meshes.reserve(numMeshes);

    // Allocate the scene root node
    pScene->mRootNode = new aiNode();

    aiColor3D fgColor(0.6f, 0.6f, 0.6f);

    // Now read all file chunks
    while (true) {
        if (stream.GetRemainingSize() < 1) break;
        char c = stream.GetI1();
        switch (c) {
            // Meshes chunk
        case 'm': {
            for (unsigned int quak = 0; quak < numMeshes; ++quak) {
                meshes.push_back(Mesh());
                Mesh &mesh = meshes.back();

                // read all vertices
                unsigned int numVerts = (unsigned int)stream.GetI4();
                if (!numVerts)
                    throw DeadlyImportError("Quick3D: Found mesh with zero vertices");

                std::vector<aiVector3D> &verts = mesh.verts;
                verts.resize(numVerts);

                for (unsigned int i = 0; i < numVerts; ++i) {
                    verts[i].x = stream.GetF4();
                    verts[i].y = stream.GetF4();
                    verts[i].z = stream.GetF4();
                }

                // read all faces
                numVerts = (unsigned int)stream.GetI4();
                if (!numVerts)
                    throw DeadlyImportError("Quick3D: Found mesh with zero faces");

                std::vector<Face> &faces = mesh.faces;
                faces.reserve(numVerts);

                // number of indices
                for (unsigned int i = 0; i < numVerts; ++i) {
                    faces.push_back(Face(stream.GetI2()));
                    if (faces.back().indices.empty())
                        throw DeadlyImportError("Quick3D: Found face with zero indices");
                }

                // indices
                for (unsigned int i = 0; i < numVerts; ++i) {
                    Face &vec = faces[i];
                    for (unsigned int a = 0; a < (unsigned int)vec.indices.size(); ++a)
                        vec.indices[a] = stream.GetI4();
                }

                // material indices
                for (unsigned int i = 0; i < numVerts; ++i) {
                    faces[i].mat = (unsigned int)stream.GetI4();
                }

                // read all normals
                numVerts = (unsigned int)stream.GetI4();
                std::vector<aiVector3D> &normals = mesh.normals;
                normals.resize(numVerts);

                for (unsigned int i = 0; i < numVerts; ++i) {
                    normals[i].x = stream.GetF4();
                    normals[i].y = stream.GetF4();
                    normals[i].z = stream.GetF4();
                }

                numVerts = (unsigned int)stream.GetI4();
                if (numTextures && numVerts) {
                    // read all texture coordinates
                    std::vector<aiVector3D> &uv = mesh.uv;
                    uv.resize(numVerts);

                    for (unsigned int i = 0; i < numVerts; ++i) {
                        uv[i].x = stream.GetF4();
                        uv[i].y = stream.GetF4();
                    }

                    // UV indices
                    for (unsigned int i = 0; i < (unsigned int)faces.size(); ++i) {
                        Face &vec = faces[i];
                        for (unsigned int a = 0; a < (unsigned int)vec.indices.size(); ++a) {
                            vec.uvindices[a] = stream.GetI4();
                            if (!i && !a)
                                mesh.prevUVIdx = vec.uvindices[a];
                            else if (vec.uvindices[a] != mesh.prevUVIdx)
                                mesh.prevUVIdx = UINT_MAX;
                        }
                    }
                }

                // we don't need the rest, but we need to get to the next chunk
                stream.IncPtr(36);
                if (minor > '0' && major == '3')
                    stream.IncPtr(mesh.faces.size());
            }
            // stream.IncPtr(4); // unknown value here
        } break;

            // materials chunk
        case 'c':

            for (unsigned int i = 0; i < numMats; ++i) {
                materials.push_back(Material());
                Material &mat = materials.back();

                // read the material name
                c = stream.GetI1();
                while (c) {
                    mat.name.data[mat.name.length++] = c;
                    c = stream.GetI1();
                }

                // add the terminal character
                mat.name.data[mat.name.length] = '\0';

                // read the ambient color
                mat.ambient.r = stream.GetF4();
                mat.ambient.g = stream.GetF4();
                mat.ambient.b = stream.GetF4();

                // read the diffuse color
                mat.diffuse.r = stream.GetF4();
                mat.diffuse.g = stream.GetF4();
                mat.diffuse.b = stream.GetF4();

                // read the ambient color
                mat.specular.r = stream.GetF4();
                mat.specular.g = stream.GetF4();
                mat.specular.b = stream.GetF4();

                // read the transparency
                mat.transparency = stream.GetF4();

                // unknown value here
                // stream.IncPtr(4);
                // FIX: it could be the texture index ...
                mat.texIdx = (unsigned int)stream.GetI4();
            }

            break;

            // texture chunk
        case 't':

            pScene->mNumTextures = numTextures;
            if (!numTextures) {
                break;
            }
            pScene->mTextures = new aiTexture *[pScene->mNumTextures];
            // to make sure we won't crash if we leave through an exception
            ::memset(pScene->mTextures, 0, sizeof(void *) * pScene->mNumTextures);
            for (unsigned int i = 0; i < pScene->mNumTextures; ++i) {
                aiTexture *tex = pScene->mTextures[i] = new aiTexture;

                // skip the texture name
                while (stream.GetI1())
                    ;

                // read texture width and height
                tex->mWidth = (unsigned int)stream.GetI4();
                tex->mHeight = (unsigned int)stream.GetI4();

                if (!tex->mWidth || !tex->mHeight) {
                    throw DeadlyImportError("Quick3D: Invalid texture. Width or height is zero");
                }

                unsigned int mul = tex->mWidth * tex->mHeight;
                aiTexel *begin = tex->pcData = new aiTexel[mul];
                aiTexel *const end = &begin[mul - 1] + 1;

                for (; begin != end; ++begin) {
                    begin->r = stream.GetI1();
                    begin->g = stream.GetI1();
                    begin->b = stream.GetI1();
                    begin->a = 0xff;
                }
            }

            break;

            // scene chunk
        case 's': {
            // skip position and rotation
            stream.IncPtr(12);

            for (unsigned int i = 0; i < 4; ++i)
                for (unsigned int a = 0; a < 4; ++a)
                    pScene->mRootNode->mTransformation[i][a] = stream.GetF4();

            stream.IncPtr(16);

            // now setup a single camera
            pScene->mNumCameras = 1;
            pScene->mCameras = new aiCamera *[1];
            aiCamera *cam = pScene->mCameras[0] = new aiCamera();
            cam->mPosition.x = stream.GetF4();
            cam->mPosition.y = stream.GetF4();
            cam->mPosition.z = stream.GetF4();
            cam->mName.Set("Q3DCamera");

            // skip eye rotation for the moment
            stream.IncPtr(12);

            // read the default material color
            fgColor.r = stream.GetF4();
            fgColor.g = stream.GetF4();
            fgColor.b = stream.GetF4();

            // skip some unimportant properties
            stream.IncPtr(29);

            // setup a single point light with no attenuation
            pScene->mNumLights = 1;
            pScene->mLights = new aiLight *[1];
            aiLight *light = pScene->mLights[0] = new aiLight();
            light->mName.Set("Q3DLight");
            light->mType = aiLightSource_POINT;

            light->mAttenuationConstant = 1;
            light->mAttenuationLinear = 0;
            light->mAttenuationQuadratic = 0;

            light->mColorDiffuse.r = stream.GetF4();
            light->mColorDiffuse.g = stream.GetF4();
            light->mColorDiffuse.b = stream.GetF4();

            light->mColorSpecular = light->mColorDiffuse;

            // We don't need the rest, but we need to know where this chunk ends.
            unsigned int temp = (unsigned int)(stream.GetI4() * stream.GetI4());

            // skip the background file name
            while (stream.GetI1())
                ;

            // skip background texture data + the remaining fields
            stream.IncPtr(temp * 3 + 20); // 4 bytes of unknown data here

            // TODO
            goto outer;
        } break;

        default:
            throw DeadlyImportError("Quick3D: Unknown chunk");
            break;
        };
    }
outer:

    // If we have no mesh loaded - break here
    if (meshes.empty())
        throw DeadlyImportError("Quick3D: No meshes loaded");

    // If we have no materials loaded - generate a default mat
    if (materials.empty()) {
        ASSIMP_LOG_INFO("Quick3D: No material found, generating one");
        materials.push_back(Material());
        materials.back().diffuse = fgColor;
    }

    // find out which materials we'll need
    typedef std::pair<unsigned int, unsigned int> FaceIdx;
    typedef std::vector<FaceIdx> FaceIdxArray;
    FaceIdxArray *fidx = new FaceIdxArray[materials.size()];

    unsigned int p = 0;
    for (std::vector<Mesh>::iterator it = meshes.begin(), end = meshes.end();
            it != end; ++it, ++p) {
        unsigned int q = 0;
        for (std::vector<Face>::iterator fit = (*it).faces.begin(), fend = (*it).faces.end();
                fit != fend; ++fit, ++q) {
            if ((*fit).mat >= materials.size()) {
                ASSIMP_LOG_WARN("Quick3D: Material index overflow");
                (*fit).mat = 0;
            }
            if (fidx[(*fit).mat].empty()) ++pScene->mNumMeshes;
            fidx[(*fit).mat].push_back(FaceIdx(p, q));
        }
    }
    pScene->mNumMaterials = pScene->mNumMeshes;
    pScene->mMaterials = new aiMaterial *[pScene->mNumMaterials];
    pScene->mMeshes = new aiMesh *[pScene->mNumMaterials];

    for (unsigned int i = 0, real = 0; i < (unsigned int)materials.size(); ++i) {
        if (fidx[i].empty()) continue;

        // Allocate a mesh and a material
        aiMesh *mesh = pScene->mMeshes[real] = new aiMesh();
        aiMaterial *mat = new aiMaterial();
        pScene->mMaterials[real] = mat;

        mesh->mMaterialIndex = real;

        // Build the output material
        Material &srcMat = materials[i];
        mat->AddProperty(&srcMat.diffuse, 1, AI_MATKEY_COLOR_DIFFUSE);
        mat->AddProperty(&srcMat.specular, 1, AI_MATKEY_COLOR_SPECULAR);
        mat->AddProperty(&srcMat.ambient, 1, AI_MATKEY_COLOR_AMBIENT);

        // NOTE: Ignore transparency for the moment - it seems
        // unclear how to interpret the data
#if 0
        if (!(minor > '0' && major == '3'))
            srcMat.transparency = 1.0f - srcMat.transparency;
        mat->AddProperty(&srcMat.transparency, 1, AI_MATKEY_OPACITY);
#endif

        // add shininess - Quick3D seems to use it ins its viewer
        srcMat.transparency = 16.f;
        mat->AddProperty(&srcMat.transparency, 1, AI_MATKEY_SHININESS);

        int m = (int)aiShadingMode_Phong;
        mat->AddProperty(&m, 1, AI_MATKEY_SHADING_MODEL);

        if (srcMat.name.length)
            mat->AddProperty(&srcMat.name, AI_MATKEY_NAME);

        // Add a texture
        if (srcMat.texIdx < pScene->mNumTextures || real < pScene->mNumTextures) {
            srcMat.name.data[0] = '*';
            srcMat.name.length = ASSIMP_itoa10(&srcMat.name.data[1], 1000,
                    (srcMat.texIdx < pScene->mNumTextures ? srcMat.texIdx : real));
            mat->AddProperty(&srcMat.name, AI_MATKEY_TEXTURE_DIFFUSE(0));
        }

        mesh->mNumFaces = (unsigned int)fidx[i].size();
        aiFace *faces = mesh->mFaces = new aiFace[mesh->mNumFaces];

        // Now build the output mesh. First find out how many
        // vertices we'll need
        for (FaceIdxArray::const_iterator it = fidx[i].begin(), end = fidx[i].end();
                it != end; ++it) {
            mesh->mNumVertices += (unsigned int)meshes[(*it).first].faces[(*it).second].indices.size();
        }

        aiVector3D *verts = mesh->mVertices = new aiVector3D[mesh->mNumVertices];
        aiVector3D *norms = mesh->mNormals = new aiVector3D[mesh->mNumVertices];
        aiVector3D *uv = nullptr;
        if (real < pScene->mNumTextures) {
            uv = mesh->mTextureCoords[0] = new aiVector3D[mesh->mNumVertices];
            mesh->mNumUVComponents[0] = 2;
        }

        // Build the final array
        unsigned int cnt = 0;
        for (FaceIdxArray::const_iterator it = fidx[i].begin(), end = fidx[i].end();
                it != end; ++it, ++faces) {
            Mesh &curMesh = meshes[(*it).first];
            Face &face = curMesh.faces[(*it).second];
            faces->mNumIndices = (unsigned int)face.indices.size();
            faces->mIndices = new unsigned int[faces->mNumIndices];

            aiVector3D faceNormal;
            bool fnOK = false;

            for (unsigned int n = 0; n < faces->mNumIndices; ++n, ++cnt, ++norms, ++verts) {
                if (face.indices[n] >= curMesh.verts.size()) {
                    ASSIMP_LOG_WARN("Quick3D: Vertex index overflow");
                    face.indices[n] = 0;
                }

                // copy vertices
                *verts = curMesh.verts[face.indices[n]];

                if (face.indices[n] >= curMesh.normals.size() && faces->mNumIndices >= 3) {
                    // we have no normal here - assign the face normal
                    if (!fnOK) {
                        const aiVector3D &pV1 = curMesh.verts[face.indices[0]];
                        const aiVector3D &pV2 = curMesh.verts[face.indices[1]];
                        const aiVector3D &pV3 = curMesh.verts[face.indices.size() - 1];
                        faceNormal = (pV2 - pV1) ^ (pV3 - pV1).Normalize();
                        fnOK = true;
                    }
                    *norms = faceNormal;
                } else {
                    *norms = curMesh.normals[face.indices[n]];
                }

                // copy texture coordinates
                if (uv && curMesh.uv.size()) {
                    if (curMesh.prevUVIdx != 0xffffffff && curMesh.uv.size() >= curMesh.verts.size()) // workaround
                    {
                        *uv = curMesh.uv[face.indices[n]];
                    } else {
                        if (face.uvindices[n] >= curMesh.uv.size()) {
                            ASSIMP_LOG_WARN("Quick3D: Texture coordinate index overflow");
                            face.uvindices[n] = 0;
                        }
                        *uv = curMesh.uv[face.uvindices[n]];
                    }
                    uv->y = 1.f - uv->y;
                    ++uv;
                }

                // setup the new vertex index
                faces->mIndices[n] = cnt;
            }
        }
        ++real;
    }

    // Delete our nice helper array
    delete[] fidx;

    // Now we need to attach the meshes to the root node of the scene
    pScene->mRootNode->mNumMeshes = pScene->mNumMeshes;
    pScene->mRootNode->mMeshes = new unsigned int[pScene->mNumMeshes];
    for (unsigned int i = 0; i < pScene->mNumMeshes; ++i)
        pScene->mRootNode->mMeshes[i] = i;

    /*pScene->mRootNode->mTransformation *= aiMatrix4x4(
        1.f, 0.f, 0.f, 0.f,
        0.f, -1.f,0.f, 0.f,
        0.f, 0.f, 1.f, 0.f,
        0.f, 0.f, 0.f, 1.f);*/

    // Add cameras and light sources to the scene root node
    pScene->mRootNode->mNumChildren = pScene->mNumLights + pScene->mNumCameras;
    if (pScene->mRootNode->mNumChildren) {
        pScene->mRootNode->mChildren = new aiNode *[pScene->mRootNode->mNumChildren];

        // the light source
        aiNode *nd = pScene->mRootNode->mChildren[0] = new aiNode();
        nd->mParent = pScene->mRootNode;
        nd->mName.Set("Q3DLight");
        nd->mTransformation = pScene->mRootNode->mTransformation;
        nd->mTransformation.Inverse();

        // camera
        nd = pScene->mRootNode->mChildren[1] = new aiNode();
        nd->mParent = pScene->mRootNode;
        nd->mName.Set("Q3DCamera");
        nd->mTransformation = pScene->mRootNode->mChildren[0]->mTransformation;
    }
}

