Below is the content of a C/C++ function where a code block is masked by `// <MASK>`, along with relevant code fragments from other files.
```
void avcodec_align_dimensions2(AVCodecContext *codeccontext, int *width, int *height,
                               int linesize_align[AV_NUM_DATA_POINTERS])
{
    int i;
    int w_align = 1;
    int h_align = 1;
    AVPixFmtDescriptor const *desc = av_pix_fmt_desc_get(codeccontext->pix_fmt);

    if (desc) {
        w_align = 1 << desc->log2_chroma_w;
        h_align = 1 << desc->log2_chroma_h;
    }

    switch (codeccontext->pix_fmt) {
    case AV_PIX_FMT_YUV420P:
    case AV_PIX_FMT_YUYV422:
    case AV_PIX_FMT_YVYU422:
    case AV_PIX_FMT_UYVY422:
    case AV_PIX_FMT_YUV422P:
    case AV_PIX_FMT_YUV440P:
    case AV_PIX_FMT_YUV444P:
    case AV_PIX_FMT_GBRP:
    case AV_PIX_FMT_GBRAP:
    case AV_PIX_FMT_GRAY8:
    case AV_PIX_FMT_GRAY16BE:
    case AV_PIX_FMT_GRAY16LE:
    case AV_PIX_FMT_YUVJ420P:
    case AV_PIX_FMT_YUVJ422P:
    case AV_PIX_FMT_YUVJ440P:
    case AV_PIX_FMT_YUVJ444P:
    case AV_PIX_FMT_YUVA420P:
    case AV_PIX_FMT_YUVA422P:
    case AV_PIX_FMT_YUVA444P:
    case AV_PIX_FMT_YUV420P9LE:
    case AV_PIX_FMT_YUV420P9BE:
    case AV_PIX_FMT_YUV420P10LE:
    case AV_PIX_FMT_YUV420P10BE:
    case AV_PIX_FMT_YUV420P12LE:
    case AV_PIX_FMT_YUV420P12BE:
    case AV_PIX_FMT_YUV420P14LE:
    case AV_PIX_FMT_YUV420P14BE:
    case AV_PIX_FMT_YUV420P16LE:
    case AV_PIX_FMT_YUV420P16BE:
    case AV_PIX_FMT_YUVA420P9LE:
    case AV_PIX_FMT_YUVA420P9BE:
    case AV_PIX_FMT_YUVA420P10LE:
    case AV_PIX_FMT_YUVA420P10BE:
    case AV_PIX_FMT_YUVA420P16LE:
    case AV_PIX_FMT_YUVA420P16BE:
    case AV_PIX_FMT_YUV422P9LE:
    case AV_PIX_FMT_YUV422P9BE:
    case AV_PIX_FMT_YUV422P10LE:
    case AV_PIX_FMT_YUV422P10BE:
    case AV_PIX_FMT_YUV422P12LE:
    case AV_PIX_FMT_YUV422P12BE:
    case AV_PIX_FMT_YUV422P14LE:
    case AV_PIX_FMT_YUV422P14BE:
    case AV_PIX_FMT_YUV422P16LE:
    case AV_PIX_FMT_YUV422P16BE:
    case AV_PIX_FMT_YUVA422P9LE:
    case AV_PIX_FMT_YUVA422P9BE:
    case AV_PIX_FMT_YUVA422P10LE:
    case AV_PIX_FMT_YUVA422P10BE:
    case AV_PIX_FMT_YUVA422P12LE:
    case AV_PIX_FMT_YUVA422P12BE:
    case AV_PIX_FMT_YUVA422P16LE:
    case AV_PIX_FMT_YUVA422P16BE:
    case AV_PIX_FMT_YUV440P10LE:
    case AV_PIX_FMT_YUV440P10BE:
    case AV_PIX_FMT_YUV440P12LE:
    case AV_PIX_FMT_YUV440P12BE:
    case AV_PIX_FMT_YUV444P9LE:
    case AV_PIX_FMT_YUV444P9BE:
    case AV_PIX_FMT_YUV444P10LE:
    case AV_PIX_FMT_YUV444P10BE:
    case AV_PIX_FMT_YUV444P12LE:
    case AV_PIX_FMT_YUV444P12BE:
    case AV_PIX_FMT_YUV444P14LE:
    case AV_PIX_FMT_YUV444P14BE:
    case AV_PIX_FMT_YUV444P16LE:
    case AV_PIX_FMT_YUV444P16BE:
    case AV_PIX_FMT_YUVA444P9LE:
    case AV_PIX_FMT_YUVA444P9BE:
    case AV_PIX_FMT_YUVA444P10LE:
    case AV_PIX_FMT_YUVA444P10BE:
    case AV_PIX_FMT_YUVA444P12LE:
    case AV_PIX_FMT_YUVA444P12BE:
    case AV_PIX_FMT_YUVA444P16LE:
    case AV_PIX_FMT_YUVA444P16BE:
    case AV_PIX_FMT_GBRP9LE:
    case AV_PIX_FMT_GBRP9BE:
    case AV_PIX_FMT_GBRP10LE:
    case AV_PIX_FMT_GBRP10BE:
    case AV_PIX_FMT_GBRP12LE:
    case AV_PIX_FMT_GBRP12BE:
    case AV_PIX_FMT_GBRP14LE:
    case AV_PIX_FMT_GBRP14BE:
    case AV_PIX_FMT_GBRP16LE:
    case AV_PIX_FMT_GBRP16BE:
    case AV_PIX_FMT_GBRAP12LE:
    case AV_PIX_FMT_GBRAP12BE:
    case AV_PIX_FMT_GBRAP16LE:
    case AV_PIX_FMT_GBRAP16BE:
        w_align = 16; //FIXME assume 16 pixel per macroblock
        h_align = 16 * 2; // interlaced needs 2 macroblocks height
        if (codeccontext->codec_id == AV_CODEC_ID_BINKVIDEO)
            w_align = 16*2;
        break;
    case AV_PIX_FMT_YUV411P:
    case AV_PIX_FMT_YUVJ411P:
    case AV_PIX_FMT_UYYVYY411:
        w_align = 32;
        h_align = 16 * 2;
        break;
    case AV_PIX_FMT_YUV410P:
        if (codeccontext->codec_id == AV_CODEC_ID_SVQ1) {
            w_align = 64;
            h_align = 64;
        }
        break;
    case AV_PIX_FMT_RGB555:
        if (codeccontext->codec_id == AV_CODEC_ID_RPZA) {
            w_align = 4;
            h_align = 4;
        }
        if (codeccontext->codec_id == AV_CODEC_ID_INTERPLAY_VIDEO) {
            w_align = 8;
            h_align = 8;
        }
        break;
    case AV_PIX_FMT_PAL8:
    case AV_PIX_FMT_BGR8:
    case AV_PIX_FMT_RGB8:
        if (codeccontext->codec_id == AV_CODEC_ID_SMC ||
            codeccontext->codec_id == AV_CODEC_ID_CINEPAK) {
            w_align = 4;
            h_align = 4;
        }
        if (codeccontext->codec_id == AV_CODEC_ID_JV ||
            codeccontext->codec_id == AV_CODEC_ID_ARGO ||
            codeccontext->codec_id == AV_CODEC_ID_INTERPLAY_VIDEO) {
            w_align = 8;
            h_align = 8;
        }
        if (codeccontext->codec_id == AV_CODEC_ID_MJPEG   ||
            codeccontext->codec_id == AV_CODEC_ID_MJPEGB  ||
            codeccontext->codec_id == AV_CODEC_ID_LJPEG   ||
            codeccontext->codec_id == AV_CODEC_ID_SMVJPEG ||
            codeccontext->codec_id == AV_CODEC_ID_AMV     ||
            codeccontext->codec_id == AV_CODEC_ID_SP5X    ||
            codeccontext->codec_id == AV_CODEC_ID_JPEGLS) {
            w_align =   8;
            h_align = 2*8;
        }
        break;
    case AV_PIX_FMT_BGR24:
        if ((codeccontext->codec_id == AV_CODEC_ID_MSZH) ||
            (codeccontext->codec_id == AV_CODEC_ID_ZLIB)) {
            w_align = 4;
            h_align = 4;
        }
        break;
    case AV_PIX_FMT_RGB24:
        if (codeccontext->codec_id == AV_CODEC_ID_CINEPAK) {
            w_align = 4;
            h_align = 4;
        }
        break;
    case AV_PIX_FMT_BGR0:
        if (codeccontext->codec_id == AV_CODEC_ID_ARGO) {
            w_align = 8;
            h_align = 8;
        }
        break;
    default:
        break;
    }

    if (codeccontext->codec_id == AV_CODEC_ID_IFF_ILBM) {
        w_align = FFMAX(w_align, 8);
    }

    *width  = FFALIGN(*width, w_align);
    *height = FFALIGN(*height, h_align);
    // Align the width and height to the specified w_align and h_align values. 
    // If the codec is H.264, a specific VP series codec, 
    // other relevant codec, or if low 
    // resolution is used, adjust the height by 2 to accommodate certain motion 
    // compensation edge cases. Additionally, ensure that the width is at least 
    // 32, to provide enough temporary space for edge emulation during 
    // out-of-frame motion vector processing.
    // <MASK>

    for (i = 0; i < 4; i++)
        linesize_align[i] = STRIDE_ALIGN;
}
```

```
// Here are some relevant code fragments from other files of the repo:

// the below code fragment can be found in:
// libavcodec/utils.c
void avcodec_align_dimensions(AVCodecContext *s, int *width, int *height)
{
    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(s->pix_fmt);
    int chroma_shift = desc->log2_chroma_w;
    int linesize_align[AV_NUM_DATA_POINTERS];
    int align;

    avcodec_align_dimensions2(s, width, height, linesize_align);
    align               = FFMAX(linesize_align[0], linesize_align[3]);
    linesize_align[1] <<= chroma_shift;
    linesize_align[2] <<= chroma_shift;
    align               = FFMAX3(align, linesize_align[1], linesize_align[2]);
    *width              = FFALIGN(*width, align);
}

// the below code fragment can be found in:
// libavcodec/cfhd.c
static int alloc_buffers(AVCodecContext *avctx)
{
    CFHDContext *s = avctx->priv_data;
    int i, j, ret, planes, bayer = 0;
    int chroma_x_shift, chroma_y_shift;
    unsigned k;

    if ((ret = ff_set_dimensions(avctx, s->coded_width, s->coded_height)) < 0)
        return ret;
    avctx->pix_fmt = s->coded_format;

    ff_cfhddsp_init(&s->dsp, s->bpc, avctx->pix_fmt == AV_PIX_FMT_BAYER_RGGB16);

    if ((ret = av_pix_fmt_get_chroma_sub_sample(s->coded_format,
                                                &chroma_x_shift,
                                                &chroma_y_shift)) < 0)
        return ret;
    planes = av_pix_fmt_count_planes(s->coded_format);
    if (s->coded_format == AV_PIX_FMT_BAYER_RGGB16) {
        planes = 4;
        chroma_x_shift = 1;
        chroma_y_shift = 1;
        bayer = 1;
    }

    for (i = 0; i < planes; i++) {
        int w8, h8, w4, h4, w2, h2;
        int width  = (i || bayer) ? s->coded_width  >> chroma_x_shift : s->coded_width;
        int height = (i || bayer) ? s->coded_height >> chroma_y_shift : s->coded_height;
        ptrdiff_t stride = (FFALIGN(width  / 8, 8) + 64) * 8;

        if (chroma_y_shift && !bayer)
            height = FFALIGN(height / 8, 2) * 8;
        s->plane[i].width  = width;
        s->plane[i].height = height;
        s->plane[i].stride = stride;

        w8 = FFALIGN(s->plane[i].width  / 8, 8) + 64;
        h8 = FFALIGN(height, 8) / 8;
        w4 = w8 * 2;
        h4 = h8 * 2;
        w2 = w4 * 2;
        h2 = h4 * 2;

        if (s->transform_type == 0) {
            s->plane[i].idwt_size = FFALIGN(height, 8) * stride;
            s->plane[i].idwt_buf =
                av_calloc(s->plane[i].idwt_size, sizeof(*s->plane[i].idwt_buf));
            s->plane[i].idwt_tmp =
                av_malloc_array(s->plane[i].idwt_size, sizeof(*s->plane[i].idwt_tmp));
        } else {
            s->plane[i].idwt_size = FFALIGN(height, 8) * stride * 2;
            s->plane[i].idwt_buf =
                av_calloc(s->plane[i].idwt_size, sizeof(*s->plane[i].idwt_buf));
            s->plane[i].idwt_tmp =
                av_malloc_array(s->plane[i].idwt_size, sizeof(*s->plane[i].idwt_tmp));
        }

        if (!s->plane[i].idwt_buf || !s->plane[i].idwt_tmp)
            return AVERROR(ENOMEM);

        s->plane[i].subband[0] = s->plane[i].idwt_buf;
        s->plane[i].subband[1] = s->plane[i].idwt_buf + 2 * w8 * h8;
        s->plane[i].subband[2] = s->plane[i].idwt_buf + 1 * w8 * h8;
        s->plane[i].subband[3] = s->plane[i].idwt_buf + 3 * w8 * h8;
        s->plane[i].subband[4] = s->plane[i].idwt_buf + 2 * w4 * h4;
        s->plane[i].subband[5] = s->plane[i].idwt_buf + 1 * w4 * h4;
        s->plane[i].subband[6] = s->plane[i].idwt_buf + 3 * w4 * h4;
        if (s->transform_type == 0) {
            s->plane[i].subband[7] = s->plane[i].idwt_buf + 2 * w2 * h2;
            s->plane[i].subband[8] = s->plane[i].idwt_buf + 1 * w2 * h2;
            s->plane[i].subband[9] = s->plane[i].idwt_buf + 3 * w2 * h2;
        } else {
            int16_t *frame2 =
            s->plane[i].subband[7]  = s->plane[i].idwt_buf + 4 * w2 * h2;
            s->plane[i].subband[8]  = frame2 + 2 * w4 * h4;
            s->plane[i].subband[9]  = frame2 + 1 * w4 * h4;
            s->plane[i].subband[10] = frame2 + 3 * w4 * h4;
            s->plane[i].subband[11] = frame2 + 2 * w2 * h2;
            s->plane[i].subband[12] = frame2 + 1 * w2 * h2;
            s->plane[i].subband[13] = frame2 + 3 * w2 * h2;
            s->plane[i].subband[14] = s->plane[i].idwt_buf + 2 * w2 * h2;
            s->plane[i].subband[15] = s->plane[i].idwt_buf + 1 * w2 * h2;
            s->plane[i].subband[16] = s->plane[i].idwt_buf + 3 * w2 * h2;
        }

        if (s->transform_type == 0) {
            for (j = 0; j < DWT_LEVELS; j++) {
                for (k = 0; k < FF_ARRAY_ELEMS(s->plane[i].band[j]); k++) {
                    s->plane[i].band[j][k].a_width  = w8 << j;
                    s->plane[i].band[j][k].a_height = h8 << j;
                }
            }
        } else {
            for (j = 0; j < DWT_LEVELS_3D; j++) {
                int t = j < 1 ? 0 : (j < 3 ? 1 : 2);

                for (k = 0; k < FF_ARRAY_ELEMS(s->plane[i].band[j]); k++) {
                    s->plane[i].band[j][k].a_width  = w8 << t;
                    s->plane[i].band[j][k].a_height = h8 << t;
                }
            }
        }

        /* ll2 and ll1 commented out because they are done in-place */
        s->plane[i].l_h[0] = s->plane[i].idwt_tmp;
        s->plane[i].l_h[1] = s->plane[i].idwt_tmp + 2 * w8 * h8;
        // s->plane[i].l_h[2] = ll2;
        s->plane[i].l_h[3] = s->plane[i].idwt_tmp;
        s->plane[i].l_h[4] = s->plane[i].idwt_tmp + 2 * w4 * h4;
        // s->plane[i].l_h[5] = ll1;
        s->plane[i].l_h[6] = s->plane[i].idwt_tmp;
        s->plane[i].l_h[7] = s->plane[i].idwt_tmp + 2 * w2 * h2;
        if (s->transform_type != 0) {
            int16_t *frame2 = s->plane[i].idwt_tmp + 4 * w2 * h2;

            s->plane[i].l_h[8] = frame2;
            s->plane[i].l_h[9] = frame2 + 2 * w2 * h2;
        }
    }

    s->a_transform_type = s->transform_type;
    s->a_height = s->coded_height;
    s->a_width  = s->coded_width;
    s->a_format = s->coded_format;

    return 0;
}

// the below code fragment can be found in:
// libavcodec/utils.c
int ff_set_dimensions(AVCodecContext *s, int width, int height)
{
    int ret = av_image_check_size2(width, height, s->max_pixels, AV_PIX_FMT_NONE, 0, s);

    if (ret < 0)
        width = height = 0;

    s->coded_width  = width;
    s->coded_height = height;
    s->width        = AV_CEIL_RSHIFT(width,  s->lowres);
    s->height       = AV_CEIL_RSHIFT(height, s->lowres);

    return ret;
}

// the below code fragment can be found in:
// libavcodec/hdrdec.c
static int hdr_decode_frame(AVCodecContext *avctx, AVFrame *p,
                            int *got_frame, AVPacket *avpkt)
{
    int width = 0, height = 0;
    GetByteContext gb;
    uint8_t line[512];
    float sar;
    int ret;

    bytestream2_init(&gb, avpkt->data, avpkt->size);
    hdr_get_line(&gb, line, sizeof(line));
    if (memcmp("#?RADIANCE\n", line, 11))
        return AVERROR_INVALIDDATA;

    do {
        hdr_get_line(&gb, line, sizeof(line));
        if (sscanf(line, "PIXASPECT=%f\n", &sar) == 1)
            avctx->sample_aspect_ratio = p->sample_aspect_ratio = av_inv_q(av_d2q(sar, 4096));
    } while (line[0] != '\n' && line[0]);

    hdr_get_line(&gb, line, sizeof(line));
    if (sscanf(line, "-Y %d +X %d\n", &height, &width) == 2) {
        ;
    } else if (sscanf(line, "+Y %d +X %d\n", &height, &width) == 2) {
        ;
    } else if (sscanf(line, "-Y %d -X %d\n", &height, &width) == 2) {
        ;
    } else if (sscanf(line, "+Y %d -X %d\n", &height, &width) == 2) {
        ;
    } else if (sscanf(line, "-X %d +Y %d\n", &width, &height) == 2) {
        ;
    } else if (sscanf(line, "+X %d +Y %d\n", &width, &height) == 2) {
        ;
    } else if (sscanf(line, "-X %d -Y %d\n", &width, &height) == 2) {
        ;
    } else if (sscanf(line, "+X %d -Y %d\n", &width, &height) == 2) {
        ;
    }

    if ((ret = ff_set_dimensions(avctx, width, height)) < 0)
        return ret;

    avctx->pix_fmt = AV_PIX_FMT_GBRPF32;

    if (avctx->skip_frame >= AVDISCARD_ALL)
        return avpkt->size;

    if ((ret = ff_thread_get_buffer(avctx, p, 0)) < 0)
        return ret;

    for (int y = 0; y < height; y++) {
        float *dst_r = (float *)(p->data[2] + y * p->linesize[2]);
        float *dst_g = (float *)(p->data[0] + y * p->linesize[0]);
        float *dst_b = (float *)(p->data[1] + y * p->linesize[1]);
        uint8_t *scanline = p->data[0] + y * p->linesize[0];
        int i;

        if (width < MINELEN || width > MAXELEN) {
            ret = decompress(scanline, width, &gb, scanline);
            if (ret < 0)
                return ret;
            goto convert;
        }

        i = bytestream2_peek_byte(&gb);
        if (i != 2) {
            ret = decompress(scanline, width, &gb, scanline);
            if (ret < 0)
                return ret;
            goto convert;
        }
        bytestream2_skip(&gb, 1);

        scanline[1] = bytestream2_get_byte(&gb);
        scanline[2] = bytestream2_get_byte(&gb);
        i = bytestream2_get_byte(&gb);

        if (scanline[1] != 2 || scanline[2] & 128) {
            scanline[0] = 2;
            scanline[3] = i;
            ret = decompress(scanline + 4, width - 1, &gb, scanline);
            if (ret < 0)
                return ret;
            goto convert;
        }

        for (int i = 0; i < 4; i++) {
            uint8_t *scanline = p->data[0] + y * p->linesize[0] + i;

            for (int j = 0; j < width * 4 && bytestream2_get_bytes_left(&gb) > 0;) {
                int run = bytestream2_get_byte(&gb);
                if (run > 128) {
                    uint8_t val = bytestream2_get_byte(&gb);
                    run &= 127;
                    while (run--) {
                        if (j >= width * 4)
                            break;
                        scanline[j] = val;
                        j += 4;
                    }
                } else if (run > 0) {
                    while (run--) {
                        if (j >= width * 4)
                            break;
                        scanline[j] = bytestream2_get_byte(&gb);
                        j += 4;
                    }
                }
            }
        }

convert:
        for (int x = 0; x < width; x++) {
            uint8_t rgbe[4];
            int expo;

            memcpy(rgbe, p->data[0] + y * p->linesize[0] + x * 4, 4);
            expo = rgbe[3] - 128;

            dst_r[x] = convert(expo, rgbe[0]);
            dst_b[x] = convert(expo, rgbe[2]);
            dst_g[x] = convert(expo, rgbe[1]);
        }
    }

    p->key_frame = 1;
    p->pict_type = AV_PICTURE_TYPE_I;

    *got_frame   = 1;

    return avpkt->size;
}

// the below code fragment can be found in:
// libavcodec/bmp.c
static int bmp_decode_frame(AVCodecContext *avctx, AVFrame *p,
                            int *got_frame, AVPacket *avpkt)
{
    const uint8_t *buf = avpkt->data;
    int buf_size       = avpkt->size;
    unsigned int fsize, hsize;
    int width, height;
    unsigned int depth;
    BiCompression comp;
    unsigned int ihsize;
    int i, j, n, linesize, ret;
    uint32_t rgb[3] = {0};
    uint32_t alpha = 0;
    uint8_t *ptr;
    int dsize;
    const uint8_t *buf0 = buf;
    GetByteContext gb;

    if (buf_size < 14) {
        av_log(avctx, AV_LOG_ERROR, "buf size too small (%d)\n", buf_size);
        return AVERROR_INVALIDDATA;
    }

    if (bytestream_get_byte(&buf) != 'B' ||
        bytestream_get_byte(&buf) != 'M') {
        av_log(avctx, AV_LOG_ERROR, "bad magic number\n");
        return AVERROR_INVALIDDATA;
    }

    fsize = bytestream_get_le32(&buf);
    if (buf_size < fsize) {
        av_log(avctx, AV_LOG_ERROR, "not enough data (%d < %u), trying to decode anyway\n",
               buf_size, fsize);
        fsize = buf_size;
    }

    buf += 2; /* reserved1 */
    buf += 2; /* reserved2 */

    hsize  = bytestream_get_le32(&buf); /* header size */
    ihsize = bytestream_get_le32(&buf); /* more header size */
    if (ihsize + 14LL > hsize) {
        av_log(avctx, AV_LOG_ERROR, "invalid header size %u\n", hsize);
        return AVERROR_INVALIDDATA;
    }

    /* sometimes file size is set to some headers size, set a real size in that case */
    if (fsize == 14 || fsize == ihsize + 14)
        fsize = buf_size - 2;

    if (fsize <= hsize) {
        av_log(avctx, AV_LOG_ERROR,
               "Declared file size is less than header size (%u < %u)\n",
               fsize, hsize);
        return AVERROR_INVALIDDATA;
    }

    switch (ihsize) {
    case  40: // windib
    case  56: // windib v3
    case  64: // OS/2 v2
    case 108: // windib v4
    case 124: // windib v5
        width  = bytestream_get_le32(&buf);
        height = bytestream_get_le32(&buf);
        break;
    case  12: // OS/2 v1
        width  = bytestream_get_le16(&buf);
        height = bytestream_get_le16(&buf);
        break;
    default:
        avpriv_report_missing_feature(avctx, "Information header size %u",
                                      ihsize);
        return AVERROR_PATCHWELCOME;
    }

    /* planes */
    if (bytestream_get_le16(&buf) != 1) {
        av_log(avctx, AV_LOG_ERROR, "invalid BMP header\n");
        return AVERROR_INVALIDDATA;
    }

    depth = bytestream_get_le16(&buf);

    if (ihsize >= 40)
        comp = bytestream_get_le32(&buf);
    else
        comp = BMP_RGB;

    if (comp != BMP_RGB && comp != BMP_BITFIELDS && comp != BMP_RLE4 &&
        comp != BMP_RLE8) {
        av_log(avctx, AV_LOG_ERROR, "BMP coding %d not supported\n", comp);
        return AVERROR_INVALIDDATA;
    }

    if (comp == BMP_BITFIELDS) {
        buf += 20;
        rgb[0] = bytestream_get_le32(&buf);
        rgb[1] = bytestream_get_le32(&buf);
        rgb[2] = bytestream_get_le32(&buf);
        if (ihsize > 40)
        alpha = bytestream_get_le32(&buf);
    }

    ret = ff_set_dimensions(avctx, width, height > 0 ? height : -(unsigned)height);
    if (ret < 0) {
        av_log(avctx, AV_LOG_ERROR, "Failed to set dimensions %d %d\n", width, height);
        return AVERROR_INVALIDDATA;
    }

    avctx->pix_fmt = AV_PIX_FMT_NONE;

    switch (depth) {
    case 32:
        if (comp == BMP_BITFIELDS) {
            if (rgb[0] == 0xFF000000 && rgb[1] == 0x00FF0000 && rgb[2] == 0x0000FF00)
                avctx->pix_fmt = alpha ? AV_PIX_FMT_ABGR : AV_PIX_FMT_0BGR;
            else if (rgb[0] == 0x00FF0000 && rgb[1] == 0x0000FF00 && rgb[2] == 0x000000FF)
                avctx->pix_fmt = alpha ? AV_PIX_FMT_BGRA : AV_PIX_FMT_BGR0;
            else if (rgb[0] == 0x0000FF00 && rgb[1] == 0x00FF0000 && rgb[2] == 0xFF000000)
                avctx->pix_fmt = alpha ? AV_PIX_FMT_ARGB : AV_PIX_FMT_0RGB;
            else if (rgb[0] == 0x000000FF && rgb[1] == 0x0000FF00 && rgb[2] == 0x00FF0000)
                avctx->pix_fmt = alpha ? AV_PIX_FMT_RGBA : AV_PIX_FMT_RGB0;
            else {
                av_log(avctx, AV_LOG_ERROR, "Unknown bitfields "
                       "%0"PRIX32" %0"PRIX32" %0"PRIX32"\n", rgb[0], rgb[1], rgb[2]);
                return AVERROR(EINVAL);
            }
        } else {
            avctx->pix_fmt = AV_PIX_FMT_BGRA;
        }
        break;
    case 24:
        avctx->pix_fmt = AV_PIX_FMT_BGR24;
        break;
    case 16:
        if (comp == BMP_RGB)
            avctx->pix_fmt = AV_PIX_FMT_RGB555;
        else if (comp == BMP_BITFIELDS) {
            if (rgb[0] == 0xF800 && rgb[1] == 0x07E0 && rgb[2] == 0x001F)
               avctx->pix_fmt = AV_PIX_FMT_RGB565;
            else if (rgb[0] == 0x7C00 && rgb[1] == 0x03E0 && rgb[2] == 0x001F)
               avctx->pix_fmt = AV_PIX_FMT_RGB555;
            else if (rgb[0] == 0x0F00 && rgb[1] == 0x00F0 && rgb[2] == 0x000F)
               avctx->pix_fmt = AV_PIX_FMT_RGB444;
            else {
               av_log(avctx, AV_LOG_ERROR,
                      "Unknown bitfields %0"PRIX32" %0"PRIX32" %0"PRIX32"\n",
                      rgb[0], rgb[1], rgb[2]);
               return AVERROR(EINVAL);
            }
        }
        break;
    case 8:
        if (hsize - ihsize - 14 > 0)
            avctx->pix_fmt = AV_PIX_FMT_PAL8;
        else
            avctx->pix_fmt = AV_PIX_FMT_GRAY8;
        break;
    case 1:
    case 4:
        if (hsize - ihsize - 14 > 0) {
            avctx->pix_fmt = AV_PIX_FMT_PAL8;
        } else {
            av_log(avctx, AV_LOG_ERROR, "Unknown palette for %u-colour BMP\n",
                   1 << depth);
            return AVERROR_INVALIDDATA;
        }
        break;
    default:
        av_log(avctx, AV_LOG_ERROR, "depth %u not supported\n", depth);
        return AVERROR_INVALIDDATA;
    }

    if (avctx->pix_fmt == AV_PIX_FMT_NONE) {
        av_log(avctx, AV_LOG_ERROR, "unsupported pixel format\n");
        return AVERROR_INVALIDDATA;
    }

    if ((ret = ff_get_buffer(avctx, p, 0)) < 0)
        return ret;
    p->pict_type = AV_PICTURE_TYPE_I;
    p->key_frame = 1;

    buf   = buf0 + hsize;
    dsize = buf_size - hsize;

    /* Line size in file multiple of 4 */
    n = ((avctx->width * depth + 31) / 8) & ~3;

    if (n * avctx->height > dsize && comp != BMP_RLE4 && comp != BMP_RLE8) {
        n = (avctx->width * depth + 7) / 8;
        if (n * avctx->height > dsize) {
            av_log(avctx, AV_LOG_ERROR, "not enough data (%d < %d)\n",
                   dsize, n * avctx->height);
            return AVERROR_INVALIDDATA;
        }
        av_log(avctx, AV_LOG_ERROR, "data size too small, assuming missing line alignment\n");
    }

    // RLE may skip decoding some picture areas, so blank picture before decoding
    if (comp == BMP_RLE4 || comp == BMP_RLE8)
        memset(p->data[0], 0, avctx->height * p->linesize[0]);

    if (height > 0) {
        ptr      = p->data[0] + (avctx->height - 1) * p->linesize[0];
        linesize = -p->linesize[0];
    } else {
        ptr      = p->data[0];
        linesize = p->linesize[0];
    }

    if (avctx->pix_fmt == AV_PIX_FMT_PAL8) {
        int colors = 1 << depth;

        memset(p->data[1], 0, 1024);

        if (ihsize >= 36) {
            int t;
            buf = buf0 + 46;
            t   = bytestream_get_le32(&buf);
            if (t < 0 || t > (1 << depth)) {
                av_log(avctx, AV_LOG_ERROR,
                       "Incorrect number of colors - %X for bitdepth %u\n",
                       t, depth);
            } else if (t) {
                colors = t;
            }
        } else {
            colors = FFMIN(256, (hsize-ihsize-14) / 3);
        }
        buf = buf0 + 14 + ihsize; //palette location
        // OS/2 bitmap, 3 bytes per palette entry
        if ((hsize-ihsize-14) < (colors << 2)) {
            if ((hsize-ihsize-14) < colors * 3) {
                av_log(avctx, AV_LOG_ERROR, "palette doesn't fit in packet\n");
                return AVERROR_INVALIDDATA;
            }
            for (i = 0; i < colors; i++)
                ((uint32_t*)p->data[1])[i] = (0xFFU<<24) | bytestream_get_le24(&buf);
        } else {
            for (i = 0; i < colors; i++)
                ((uint32_t*)p->data[1])[i] = 0xFFU << 24 | bytestream_get_le32(&buf);
        }
        buf = buf0 + hsize;
    }
    if (comp == BMP_RLE4 || comp == BMP_RLE8) {
        if (comp == BMP_RLE8 && height < 0) {
            p->data[0]    +=  p->linesize[0] * (avctx->height - 1);
            p->linesize[0] = -p->linesize[0];
        }
        bytestream2_init(&gb, buf, dsize);
        ff_msrle_decode(avctx, p, depth, &gb);
        if (height < 0) {
            p->data[0]    +=  p->linesize[0] * (avctx->height - 1);
            p->linesize[0] = -p->linesize[0];
        }
    } else {
        switch (depth) {
        case 1:
            for (i = 0; i < avctx->height; i++) {
                int j;
                for (j = 0; j < avctx->width >> 3; j++) {
                    ptr[j*8+0] =  buf[j] >> 7;
                    ptr[j*8+1] = (buf[j] >> 6) & 1;
                    ptr[j*8+2] = (buf[j] >> 5) & 1;
                    ptr[j*8+3] = (buf[j] >> 4) & 1;
                    ptr[j*8+4] = (buf[j] >> 3) & 1;
                    ptr[j*8+5] = (buf[j] >> 2) & 1;
                    ptr[j*8+6] = (buf[j] >> 1) & 1;
                    ptr[j*8+7] =  buf[j]       & 1;
                }
                for (j = 0; j < (avctx->width & 7); j++) {
                    ptr[avctx->width - (avctx->width & 7) + j] = buf[avctx->width >> 3] >> (7 - j) & 1;
                }
                buf += n;
                ptr += linesize;
            }
            break;
        case 8:
        case 24:
        case 32:
            for (i = 0; i < avctx->height; i++) {
                memcpy(ptr, buf, n);
                buf += n;
                ptr += linesize;
            }
            break;
        case 4:
            for (i = 0; i < avctx->height; i++) {
                int j;
                for (j = 0; j < n; j++) {
                    ptr[j*2+0] = (buf[j] >> 4) & 0xF;
                    ptr[j*2+1] = buf[j] & 0xF;
                }
                buf += n;
                ptr += linesize;
            }
            break;
        case 16:
            for (i = 0; i < avctx->height; i++) {
                const uint16_t *src = (const uint16_t *) buf;
                uint16_t *dst       = (uint16_t *) ptr;

                for (j = 0; j < avctx->width; j++)
                    *dst++ = av_le2ne16(*src++);

                buf += n;
                ptr += linesize;
            }
            break;
        default:
            av_log(avctx, AV_LOG_ERROR, "BMP decoder is broken\n");
            return AVERROR_INVALIDDATA;
        }
    }
    if (avctx->pix_fmt == AV_PIX_FMT_BGRA) {
        for (i = 0; i < avctx->height; i++) {
            int j;
            uint8_t *ptr = p->data[0] + p->linesize[0]*i + 3;
            for (j = 0; j < avctx->width; j++) {
                if (ptr[4*j])
                    break;
            }
            if (j < avctx->width)
                break;
        }
        if (i == avctx->height)
            avctx->pix_fmt = p->format = AV_PIX_FMT_BGR0;
    }

    *got_frame = 1;

    return buf_size;
}
```

Create a code snippet to fill in the masked region. Please wrap your answer in a code block (triple backquotes).