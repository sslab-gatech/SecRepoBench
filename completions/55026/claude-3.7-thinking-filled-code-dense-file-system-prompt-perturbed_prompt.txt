Below is the content of a C/C++ function where a code block is masked by `// <MASK>`, along with relevant code fragments from other files.
```
void avcodec_align_dimensions2(AVCodecContext *s, int *width, int *height,
                               int linesize_align[AV_NUM_DATA_POINTERS])
{
    int i;
    int w_align = 1;
    int height_align = 1;
    AVPixFmtDescriptor const *desc = av_pix_fmt_desc_get(s->pix_fmt);

    if (desc) {
        w_align = 1 << desc->log2_chroma_w;
        height_align = 1 << desc->log2_chroma_h;
    }

    switch (s->pix_fmt) {
    case AV_PIX_FMT_YUV420P:
    case AV_PIX_FMT_YUYV422:
    case AV_PIX_FMT_YVYU422:
    case AV_PIX_FMT_UYVY422:
    case AV_PIX_FMT_YUV422P:
    case AV_PIX_FMT_YUV440P:
    case AV_PIX_FMT_YUV444P:
    case AV_PIX_FMT_GBRP:
    case AV_PIX_FMT_GBRAP:
    case AV_PIX_FMT_GRAY8:
    case AV_PIX_FMT_GRAY16BE:
    case AV_PIX_FMT_GRAY16LE:
    case AV_PIX_FMT_YUVJ420P:
    case AV_PIX_FMT_YUVJ422P:
    case AV_PIX_FMT_YUVJ440P:
    case AV_PIX_FMT_YUVJ444P:
    case AV_PIX_FMT_YUVA420P:
    case AV_PIX_FMT_YUVA422P:
    case AV_PIX_FMT_YUVA444P:
    case AV_PIX_FMT_YUV420P9LE:
    case AV_PIX_FMT_YUV420P9BE:
    case AV_PIX_FMT_YUV420P10LE:
    case AV_PIX_FMT_YUV420P10BE:
    case AV_PIX_FMT_YUV420P12LE:
    case AV_PIX_FMT_YUV420P12BE:
    case AV_PIX_FMT_YUV420P14LE:
    case AV_PIX_FMT_YUV420P14BE:
    case AV_PIX_FMT_YUV420P16LE:
    case AV_PIX_FMT_YUV420P16BE:
    case AV_PIX_FMT_YUVA420P9LE:
    case AV_PIX_FMT_YUVA420P9BE:
    case AV_PIX_FMT_YUVA420P10LE:
    case AV_PIX_FMT_YUVA420P10BE:
    case AV_PIX_FMT_YUVA420P16LE:
    case AV_PIX_FMT_YUVA420P16BE:
    case AV_PIX_FMT_YUV422P9LE:
    case AV_PIX_FMT_YUV422P9BE:
    case AV_PIX_FMT_YUV422P10LE:
    case AV_PIX_FMT_YUV422P10BE:
    case AV_PIX_FMT_YUV422P12LE:
    case AV_PIX_FMT_YUV422P12BE:
    case AV_PIX_FMT_YUV422P14LE:
    case AV_PIX_FMT_YUV422P14BE:
    case AV_PIX_FMT_YUV422P16LE:
    case AV_PIX_FMT_YUV422P16BE:
    case AV_PIX_FMT_YUVA422P9LE:
    case AV_PIX_FMT_YUVA422P9BE:
    case AV_PIX_FMT_YUVA422P10LE:
    case AV_PIX_FMT_YUVA422P10BE:
    case AV_PIX_FMT_YUVA422P12LE:
    case AV_PIX_FMT_YUVA422P12BE:
    case AV_PIX_FMT_YUVA422P16LE:
    case AV_PIX_FMT_YUVA422P16BE:
    case AV_PIX_FMT_YUV440P10LE:
    case AV_PIX_FMT_YUV440P10BE:
    case AV_PIX_FMT_YUV440P12LE:
    case AV_PIX_FMT_YUV440P12BE:
    case AV_PIX_FMT_YUV444P9LE:
    case AV_PIX_FMT_YUV444P9BE:
    case AV_PIX_FMT_YUV444P10LE:
    case AV_PIX_FMT_YUV444P10BE:
    case AV_PIX_FMT_YUV444P12LE:
    case AV_PIX_FMT_YUV444P12BE:
    case AV_PIX_FMT_YUV444P14LE:
    case AV_PIX_FMT_YUV444P14BE:
    case AV_PIX_FMT_YUV444P16LE:
    case AV_PIX_FMT_YUV444P16BE:
    case AV_PIX_FMT_YUVA444P9LE:
    case AV_PIX_FMT_YUVA444P9BE:
    case AV_PIX_FMT_YUVA444P10LE:
    case AV_PIX_FMT_YUVA444P10BE:
    case AV_PIX_FMT_YUVA444P12LE:
    case AV_PIX_FMT_YUVA444P12BE:
    case AV_PIX_FMT_YUVA444P16LE:
    case AV_PIX_FMT_YUVA444P16BE:
    case AV_PIX_FMT_GBRP9LE:
    case AV_PIX_FMT_GBRP9BE:
    case AV_PIX_FMT_GBRP10LE:
    case AV_PIX_FMT_GBRP10BE:
    // Handle pixel width and height format alignment for AV_PIX_FMT_GBRP12LE, 
    // AV_PIX_FMT_GBRP12BE, AV_PIX_FMT_GBRP14LE, AV_PIX_FMT_GBRP14BE, 
    // AV_PIX_FMT_GBRP16LE, AV_PIX_FMT_GBRP16BE, AV_PIX_FMT_GBRAP12LE, 
    // AV_PIX_FMT_GBRAP12BE, AV_PIX_FMT_GBRAP16LE, and AV_PIX_FMT_GBRAP16BE.
    // <MASK>
    case AV_PIX_FMT_YUV411P:
    case AV_PIX_FMT_YUVJ411P:
    case AV_PIX_FMT_UYYVYY411:
        w_align = 32;
        height_align = 16 * 2;
        break;
    case AV_PIX_FMT_YUV410P:
        if (s->codec_id == AV_CODEC_ID_SVQ1) {
            w_align = 64;
            height_align = 64;
        }
        break;
    case AV_PIX_FMT_RGB555:
        if (s->codec_id == AV_CODEC_ID_RPZA) {
            w_align = 4;
            height_align = 4;
        }
        if (s->codec_id == AV_CODEC_ID_INTERPLAY_VIDEO) {
            w_align = 8;
            height_align = 8;
        }
        break;
    case AV_PIX_FMT_PAL8:
    case AV_PIX_FMT_BGR8:
    case AV_PIX_FMT_RGB8:
        if (s->codec_id == AV_CODEC_ID_SMC ||
            s->codec_id == AV_CODEC_ID_CINEPAK) {
            w_align = 4;
            height_align = 4;
        }
        if (s->codec_id == AV_CODEC_ID_JV ||
            s->codec_id == AV_CODEC_ID_ARGO ||
            s->codec_id == AV_CODEC_ID_INTERPLAY_VIDEO) {
            w_align = 8;
            height_align = 8;
        }
        if (s->codec_id == AV_CODEC_ID_MJPEG   ||
            s->codec_id == AV_CODEC_ID_MJPEGB  ||
            s->codec_id == AV_CODEC_ID_LJPEG   ||
            s->codec_id == AV_CODEC_ID_SMVJPEG ||
            s->codec_id == AV_CODEC_ID_AMV     ||
            s->codec_id == AV_CODEC_ID_SP5X    ||
            s->codec_id == AV_CODEC_ID_JPEGLS) {
            w_align =   8;
            height_align = 2*8;
        }
        break;
    case AV_PIX_FMT_BGR24:
        if ((s->codec_id == AV_CODEC_ID_MSZH) ||
            (s->codec_id == AV_CODEC_ID_ZLIB)) {
            w_align = 4;
            height_align = 4;
        }
        break;
    case AV_PIX_FMT_RGB24:
        if (s->codec_id == AV_CODEC_ID_CINEPAK) {
            w_align = 4;
            height_align = 4;
        }
        break;
    case AV_PIX_FMT_BGR0:
        if (s->codec_id == AV_CODEC_ID_ARGO) {
            w_align = 8;
            height_align = 8;
        }
        break;
    default:
        break;
    }

    if (s->codec_id == AV_CODEC_ID_IFF_ILBM) {
        w_align = FFMAX(w_align, 8);
    }

    *width  = FFALIGN(*width, w_align);
    *height = FFALIGN(*height, height_align);
    if (s->codec_id == AV_CODEC_ID_H264 || s->lowres ||
        s->codec_id == AV_CODEC_ID_VP5  || s->codec_id == AV_CODEC_ID_VP6 ||
        s->codec_id == AV_CODEC_ID_VP6F || s->codec_id == AV_CODEC_ID_VP6A
    ) {
        // some of the optimized chroma MC reads one line too much
        // which is also done in mpeg decoders with lowres > 0
        *height += 2;

        // H.264 uses edge emulation for out of frame motion vectors, for this
        // it requires a temporary area large enough to hold a 21x21 block,
        // increasing witdth ensure that the temporary area is large enough,
        // the next rounded up width is 32
        *width = FFMAX(*width, 32);
    }

    for (i = 0; i < 4; i++)
        linesize_align[i] = STRIDE_ALIGN;
}
```

```
// Here are some relevant code fragments from other files of the repo:

// the below code fragment can be found in:
// libavcodec/utils.c
void avcodec_align_dimensions(AVCodecContext *s, int *width, int *height)
{
    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(s->pix_fmt);
    int chroma_shift = desc->log2_chroma_w;
    int linesize_align[AV_NUM_DATA_POINTERS];
    int align;

    avcodec_align_dimensions2(s, width, height, linesize_align);
    align               = FFMAX(linesize_align[0], linesize_align[3]);
    linesize_align[1] <<= chroma_shift;
    linesize_align[2] <<= chroma_shift;
    align               = FFMAX3(align, linesize_align[1], linesize_align[2]);
    *width              = FFALIGN(*width, align);
}

// the below code fragment can be found in:
// libavcodec/cfhd.c
static int alloc_buffers(AVCodecContext *avctx)
{
    CFHDContext *s = avctx->priv_data;
    int i, j, ret, planes, bayer = 0;
    int chroma_x_shift, chroma_y_shift;
    unsigned k;

    if ((ret = ff_set_dimensions(avctx, s->coded_width, s->coded_height)) < 0)
        return ret;
    avctx->pix_fmt = s->coded_format;

    ff_cfhddsp_init(&s->dsp, s->bpc, avctx->pix_fmt == AV_PIX_FMT_BAYER_RGGB16);

    if ((ret = av_pix_fmt_get_chroma_sub_sample(s->coded_format,
                                                &chroma_x_shift,
                                                &chroma_y_shift)) < 0)
        return ret;
    planes = av_pix_fmt_count_planes(s->coded_format);
    if (s->coded_format == AV_PIX_FMT_BAYER_RGGB16) {
        planes = 4;
        chroma_x_shift = 1;
        chroma_y_shift = 1;
        bayer = 1;
    }

    for (i = 0; i < planes; i++) {
        int w8, h8, w4, h4, w2, h2;
        int width  = (i || bayer) ? s->coded_width  >> chroma_x_shift : s->coded_width;
        int height = (i || bayer) ? s->coded_height >> chroma_y_shift : s->coded_height;
        ptrdiff_t stride = (FFALIGN(width  / 8, 8) + 64) * 8;

        if (chroma_y_shift && !bayer)
            height = FFALIGN(height / 8, 2) * 8;
        s->plane[i].width  = width;
        s->plane[i].height = height;
        s->plane[i].stride = stride;

        w8 = FFALIGN(s->plane[i].width  / 8, 8) + 64;
        h8 = FFALIGN(height, 8) / 8;
        w4 = w8 * 2;
        h4 = h8 * 2;
        w2 = w4 * 2;
        h2 = h4 * 2;

        if (s->transform_type == 0) {
            s->plane[i].idwt_size = FFALIGN(height, 8) * stride;
            s->plane[i].idwt_buf =
                av_calloc(s->plane[i].idwt_size, sizeof(*s->plane[i].idwt_buf));
            s->plane[i].idwt_tmp =
                av_malloc_array(s->plane[i].idwt_size, sizeof(*s->plane[i].idwt_tmp));
        } else {
            s->plane[i].idwt_size = FFALIGN(height, 8) * stride * 2;
            s->plane[i].idwt_buf =
                av_calloc(s->plane[i].idwt_size, sizeof(*s->plane[i].idwt_buf));
            s->plane[i].idwt_tmp =
                av_malloc_array(s->plane[i].idwt_size, sizeof(*s->plane[i].idwt_tmp));
        }

        if (!s->plane[i].idwt_buf || !s->plane[i].idwt_tmp)
            return AVERROR(ENOMEM);

        s->plane[i].subband[0] = s->plane[i].idwt_buf;
        s->plane[i].subband[1] = s->plane[i].idwt_buf + 2 * w8 * h8;
        s->plane[i].subband[2] = s->plane[i].idwt_buf + 1 * w8 * h8;
        s->plane[i].subband[3] = s->plane[i].idwt_buf + 3 * w8 * h8;
        s->plane[i].subband[4] = s->plane[i].idwt_buf + 2 * w4 * h4;
        s->plane[i].subband[5] = s->plane[i].idwt_buf + 1 * w4 * h4;
        s->plane[i].subband[6] = s->plane[i].idwt_buf + 3 * w4 * h4;
        if (s->transform_type == 0) {
            s->plane[i].subband[7] = s->plane[i].idwt_buf + 2 * w2 * h2;
            s->plane[i].subband[8] = s->plane[i].idwt_buf + 1 * w2 * h2;
            s->plane[i].subband[9] = s->plane[i].idwt_buf + 3 * w2 * h2;
        } else {
            int16_t *frame2 =
            s->plane[i].subband[7]  = s->plane[i].idwt_buf + 4 * w2 * h2;
            s->plane[i].subband[8]  = frame2 + 2 * w4 * h4;
            s->plane[i].subband[9]  = frame2 + 1 * w4 * h4;
            s->plane[i].subband[10] = frame2 + 3 * w4 * h4;
            s->plane[i].subband[11] = frame2 + 2 * w2 * h2;
            s->plane[i].subband[12] = frame2 + 1 * w2 * h2;
            s->plane[i].subband[13] = frame2 + 3 * w2 * h2;
            s->plane[i].subband[14] = s->plane[i].idwt_buf + 2 * w2 * h2;
            s->plane[i].subband[15] = s->plane[i].idwt_buf + 1 * w2 * h2;
            s->plane[i].subband[16] = s->plane[i].idwt_buf + 3 * w2 * h2;
        }

        if (s->transform_type == 0) {
            for (j = 0; j < DWT_LEVELS; j++) {
                for (k = 0; k < FF_ARRAY_ELEMS(s->plane[i].band[j]); k++) {
                    s->plane[i].band[j][k].a_width  = w8 << j;
                    s->plane[i].band[j][k].a_height = h8 << j;
                }
            }
        } else {
            for (j = 0; j < DWT_LEVELS_3D; j++) {
                int t = j < 1 ? 0 : (j < 3 ? 1 : 2);

                for (k = 0; k < FF_ARRAY_ELEMS(s->plane[i].band[j]); k++) {
                    s->plane[i].band[j][k].a_width  = w8 << t;
                    s->plane[i].band[j][k].a_height = h8 << t;
                }
            }
        }

        /* ll2 and ll1 commented out because they are done in-place */
        s->plane[i].l_h[0] = s->plane[i].idwt_tmp;
        s->plane[i].l_h[1] = s->plane[i].idwt_tmp + 2 * w8 * h8;
        // s->plane[i].l_h[2] = ll2;
        s->plane[i].l_h[3] = s->plane[i].idwt_tmp;
        s->plane[i].l_h[4] = s->plane[i].idwt_tmp + 2 * w4 * h4;
        // s->plane[i].l_h[5] = ll1;
        s->plane[i].l_h[6] = s->plane[i].idwt_tmp;
        s->plane[i].l_h[7] = s->plane[i].idwt_tmp + 2 * w2 * h2;
        if (s->transform_type != 0) {
            int16_t *frame2 = s->plane[i].idwt_tmp + 4 * w2 * h2;

            s->plane[i].l_h[8] = frame2;
            s->plane[i].l_h[9] = frame2 + 2 * w2 * h2;
        }
    }

    s->a_transform_type = s->transform_type;
    s->a_height = s->coded_height;
    s->a_width  = s->coded_width;
    s->a_format = s->coded_format;

    return 0;
}

// the below code fragment can be found in:
// libavcodec/utils.c
int ff_set_dimensions(AVCodecContext *s, int width, int height)
{
    int ret = av_image_check_size2(width, height, s->max_pixels, AV_PIX_FMT_NONE, 0, s);

    if (ret < 0)
        width = height = 0;

    s->coded_width  = width;
    s->coded_height = height;
    s->width        = AV_CEIL_RSHIFT(width,  s->lowres);
    s->height       = AV_CEIL_RSHIFT(height, s->lowres);

    return ret;
}

// the below code fragment can be found in:
// libavcodec/hdrdec.c
static int hdr_decode_frame(AVCodecContext *avctx, AVFrame *p,
                            int *got_frame, AVPacket *avpkt)
{
    int width = 0, height = 0;
    GetByteContext gb;
    uint8_t line[512];
    float sar;
    int ret;

    bytestream2_init(&gb, avpkt->data, avpkt->size);
    hdr_get_line(&gb, line, sizeof(line));
    if (memcmp("#?RADIANCE\n", line, 11))
        return AVERROR_INVALIDDATA;

    do {
        hdr_get_line(&gb, line, sizeof(line));
        if (sscanf(line, "PIXASPECT=%f\n", &sar) == 1)
            avctx->sample_aspect_ratio = p->sample_aspect_ratio = av_inv_q(av_d2q(sar, 4096));
    } while (line[0] != '\n' && line[0]);

    hdr_get_line(&gb, line, sizeof(line));
    if (sscanf(line, "-Y %d +X %d\n", &height, &width) == 2) {
        ;
    } else if (sscanf(line, "+Y %d +X %d\n", &height, &width) == 2) {
        ;
    } else if (sscanf(line, "-Y %d -X %d\n", &height, &width) == 2) {
        ;
    } else if (sscanf(line, "+Y %d -X %d\n", &height, &width) == 2) {
        ;
    } else if (sscanf(line, "-X %d +Y %d\n", &width, &height) == 2) {
        ;
    } else if (sscanf(line, "+X %d +Y %d\n", &width, &height) == 2) {
        ;
    } else if (sscanf(line, "-X %d -Y %d\n", &width, &height) == 2) {
        ;
    } else if (sscanf(line, "+X %d -Y %d\n", &width, &height) == 2) {
        ;
    }

    if ((ret = ff_set_dimensions(avctx, width, height)) < 0)
        return ret;

    avctx->pix_fmt = AV_PIX_FMT_GBRPF32;

    if (avctx->skip_frame >= AVDISCARD_ALL)
        return avpkt->size;

    if ((ret = ff_thread_get_buffer(avctx, p, 0)) < 0)
        return ret;

    for (int y = 0; y < height; y++) {
        float *dst_r = (float *)(p->data[2] + y * p->linesize[2]);
        float *dst_g = (float *)(p->data[0] + y * p->linesize[0]);
        float *dst_b = (float *)(p->data[1] + y * p->linesize[1]);
        uint8_t *scanline = p->data[0] + y * p->linesize[0];
        int i;

        if (width < MINELEN || width > MAXELEN) {
            ret = decompress(scanline, width, &gb, scanline);
            if (ret < 0)
                return ret;
            goto convert;
        }

        i = bytestream2_peek_byte(&gb);
        if (i != 2) {
            ret = decompress(scanline, width, &gb, scanline);
            if (ret < 0)
                return ret;
            goto convert;
        }
        bytestream2_skip(&gb, 1);

        scanline[1] = bytestream2_get_byte(&gb);
        scanline[2] = bytestream2_get_byte(&gb);
        i = bytestream2_get_byte(&gb);

        if (scanline[1] != 2 || scanline[2] & 128) {
            scanline[0] = 2;
            scanline[3] = i;
            ret = decompress(scanline + 4, width - 1, &gb, scanline);
            if (ret < 0)
                return ret;
            goto convert;
        }

        for (int i = 0; i < 4; i++) {
            uint8_t *scanline = p->data[0] + y * p->linesize[0] + i;

            for (int j = 0; j < width * 4 && bytestream2_get_bytes_left(&gb) > 0;) {
                int run = bytestream2_get_byte(&gb);
                if (run > 128) {
                    uint8_t val = bytestream2_get_byte(&gb);
                    run &= 127;
                    while (run--) {
                        if (j >= width * 4)
                            break;
                        scanline[j] = val;
                        j += 4;
                    }
                } else if (run > 0) {
                    while (run--) {
                        if (j >= width * 4)
                            break;
                        scanline[j] = bytestream2_get_byte(&gb);
                        j += 4;
                    }
                }
            }
        }

convert:
        for (int x = 0; x < width; x++) {
            uint8_t rgbe[4];
            int expo;

            memcpy(rgbe, p->data[0] + y * p->linesize[0] + x * 4, 4);
            expo = rgbe[3] - 128;

            dst_r[x] = convert(expo, rgbe[0]);
            dst_b[x] = convert(expo, rgbe[2]);
            dst_g[x] = convert(expo, rgbe[1]);
        }
    }

    p->key_frame = 1;
    p->pict_type = AV_PICTURE_TYPE_I;

    *got_frame   = 1;

    return avpkt->size;
}

// the below code fragment can be found in:
// libavcodec/dpx.c
static int decode_frame(AVCodecContext *avctx, AVFrame *p,
                        int *got_frame, AVPacket *avpkt)
{
    const uint8_t *buf = avpkt->data;
    int buf_size       = avpkt->size;
    uint8_t *ptr[AV_NUM_DATA_POINTERS];
    uint32_t header_version, version = 0;
    char creator[101] = { 0 };
    char input_device[33] = { 0 };

    unsigned int offset;
    int magic_num, endian;
    int x, y, stride, i, j, ret;
    int w, h, bits_per_color, descriptor, elements, packing;
    int yuv, color_trc, color_spec;
    int encoding, need_align = 0, unpadded_10bit = 0;

    unsigned int rgbBuffer = 0;
    int n_datum = 0;

    if (avpkt->size <= 1634) {
        av_log(avctx, AV_LOG_ERROR, "Packet too small for DPX header\n");
        return AVERROR_INVALIDDATA;
    }

    magic_num = AV_RB32(buf);
    buf += 4;

    /* Check if the files "magic number" is "SDPX" which means it uses
     * big-endian or XPDS which is for little-endian files */
    if (magic_num == AV_RL32("SDPX")) {
        endian = 0;
    } else if (magic_num == AV_RB32("SDPX")) {
        endian = 1;
    } else {
        av_log(avctx, AV_LOG_ERROR, "DPX marker not found\n");
        return AVERROR_INVALIDDATA;
    }

    offset = read32(&buf, endian);
    if (avpkt->size <= offset) {
        av_log(avctx, AV_LOG_ERROR, "Invalid data start offset\n");
        return AVERROR_INVALIDDATA;
    }

    header_version = read32(&buf, 0);
    if (header_version == MKTAG('V','1','.','0'))
        version = 1;
    if (header_version == MKTAG('V','2','.','0'))
        version = 2;
    if (!version)
        av_log(avctx, AV_LOG_WARNING, "Unknown header format version %s.\n",
               av_fourcc2str(header_version));

    // Check encryption
    buf = avpkt->data + 660;
    ret = read32(&buf, endian);
    if (ret != 0xFFFFFFFF) {
        avpriv_report_missing_feature(avctx, "Encryption");
        av_log(avctx, AV_LOG_WARNING, "The image is encrypted and may "
               "not properly decode.\n");
    }

    // Need to end in 0x304 offset from start of file
    buf = avpkt->data + 0x304;
    w = read32(&buf, endian);
    h = read32(&buf, endian);

    if ((ret = ff_set_dimensions(avctx, w, h)) < 0)
        return ret;

    // Need to end in 0x320 to read the descriptor
    buf += 20;
    descriptor = buf[0];
    color_trc = buf[1];
    color_spec = buf[2];

    // Need to end in 0x323 to read the bits per color
    buf += 3;
    avctx->bits_per_raw_sample =
    bits_per_color = buf[0];
    buf++;
    packing = read16(&buf, endian);
    encoding = read16(&buf, endian);

    if (encoding) {
        avpriv_report_missing_feature(avctx, "Encoding %d", encoding);
        return AVERROR_PATCHWELCOME;
    }

    if (bits_per_color > 31)
        return AVERROR_INVALIDDATA;

    buf += 820;
    avctx->sample_aspect_ratio.num = read32(&buf, endian);
    avctx->sample_aspect_ratio.den = read32(&buf, endian);
    if (avctx->sample_aspect_ratio.num > 0 && avctx->sample_aspect_ratio.den > 0)
        av_reduce(&avctx->sample_aspect_ratio.num, &avctx->sample_aspect_ratio.den,
                   avctx->sample_aspect_ratio.num,  avctx->sample_aspect_ratio.den,
                  0x10000);
    else
        avctx->sample_aspect_ratio = (AVRational){ 0, 1 };

    /* preferred frame rate from Motion-picture film header */
    if (offset >= 1724 + 4) {
        buf = avpkt->data + 1724;
        i = read32(&buf, endian);
        if(i && i != 0xFFFFFFFF) {
            AVRational q = av_d2q(av_int2float(i), 4096);
            if (q.num > 0 && q.den > 0)
                avctx->framerate = q;
        }
    }

    /* alternative frame rate from television header */
    if (offset >= 1940 + 4 &&
        !(avctx->framerate.num && avctx->framerate.den)) {
        buf = avpkt->data + 1940;
        i = read32(&buf, endian);
        if(i && i != 0xFFFFFFFF) {
            AVRational q = av_d2q(av_int2float(i), 4096);
            if (q.num > 0 && q.den > 0)
                avctx->framerate = q;
        }
    }

    /* SMPTE TC from television header */
    if (offset >= 1920 + 4) {
        uint32_t tc;
        uint32_t *tc_sd;
        char tcbuf[AV_TIMECODE_STR_SIZE];

        buf = avpkt->data + 1920;
        // read32 to native endian, av_bswap32 to opposite of native for
        // compatibility with av_timecode_make_smpte_tc_string2 etc
        tc = av_bswap32(read32(&buf, endian));

        if (i != 0xFFFFFFFF) {
            AVFrameSideData *tcside =
                av_frame_new_side_data(p, AV_FRAME_DATA_S12M_TIMECODE,
                                       sizeof(uint32_t) * 4);
            if (!tcside)
                return AVERROR(ENOMEM);

            tc_sd = (uint32_t*)tcside->data;
            tc_sd[0] = 1;
            tc_sd[1] = tc;

            av_timecode_make_smpte_tc_string2(tcbuf, avctx->framerate,
                                              tc_sd[1], 0, 0);
            av_dict_set(&p->metadata, "timecode", tcbuf, 0);
        }
    }

    /* color range from television header */
    if (offset >= 1964 + 4) {
        buf = avpkt->data + 1952;
        i = read32(&buf, endian);

        buf = avpkt->data + 1964;
        j = read32(&buf, endian);

        if (i != 0xFFFFFFFF && j != 0xFFFFFFFF) {
            float minCV, maxCV;
            minCV = av_int2float(i);
            maxCV = av_int2float(j);
            if (bits_per_color >= 1 &&
                minCV == 0.0f && maxCV == ((1U<<bits_per_color) - 1)) {
                avctx->color_range = AVCOL_RANGE_JPEG;
            } else if (bits_per_color >= 8 &&
                       minCV == (1  <<(bits_per_color - 4)) &&
                       maxCV == (235<<(bits_per_color - 8))) {
                avctx->color_range = AVCOL_RANGE_MPEG;
            }
        }
    }

    switch (descriptor) {
    case 1:  // R
    case 2:  // G
    case 3:  // B
    case 4:  // A
    case 6:  // Y
        elements = 1;
        yuv = 1;
        break;
    case 50: // RGB
        elements = 3;
        yuv = 0;
        break;
    case 52: // ABGR
    case 51: // RGBA
        elements = 4;
        yuv = 0;
        break;
    case 100: // UYVY422
        elements = 2;
        yuv = 1;
        break;
    case 102: // UYV444
        elements = 3;
        yuv = 1;
        break;
    case 103: // UYVA4444
        elements = 4;
        yuv = 1;
        break;
    default:
        avpriv_report_missing_feature(avctx, "Descriptor %d", descriptor);
        return AVERROR_PATCHWELCOME;
    }

    switch (bits_per_color) {
    case 8:
        stride = avctx->width * elements;
        break;
    case 10:
        if (!packing) {
            av_log(avctx, AV_LOG_ERROR, "Packing to 32bit required\n");
            return -1;
        }
        stride = (avctx->width * elements + 2) / 3 * 4;
        break;
    case 12:
        stride = avctx->width * elements;
        if (packing) {
            stride *= 2;
        } else {
            stride *= 3;
            if (stride % 8) {
                stride /= 8;
                stride++;
                stride *= 8;
            }
            stride /= 2;
        }
        break;
    case 16:
        stride = 2 * avctx->width * elements;
        break;
    case 32:
        stride = 4 * avctx->width * elements;
        break;
    case 1:
    case 64:
        avpriv_report_missing_feature(avctx, "Depth %d", bits_per_color);
        return AVERROR_PATCHWELCOME;
    default:
        return AVERROR_INVALIDDATA;
    }

    switch (color_trc) {
    case DPX_TRC_LINEAR:
        avctx->color_trc = AVCOL_TRC_LINEAR;
        break;
    case DPX_TRC_SMPTE_274:
    case DPX_TRC_ITU_R_709_4:
        avctx->color_trc = AVCOL_TRC_BT709;
        break;
    case DPX_TRC_ITU_R_601_625:
    case DPX_TRC_ITU_R_601_525:
    case DPX_TRC_SMPTE_170:
        avctx->color_trc = AVCOL_TRC_SMPTE170M;
        break;
    case DPX_TRC_ITU_R_624_4_PAL:
        avctx->color_trc = AVCOL_TRC_GAMMA28;
        break;
    case DPX_TRC_USER_DEFINED:
    case DPX_TRC_UNSPECIFIED_VIDEO:
        /* Nothing to do */
        break;
    default:
        av_log(avctx, AV_LOG_VERBOSE, "Cannot map DPX transfer characteristic "
            "%d to color_trc.\n", color_trc);
        break;
    }

    switch (color_spec) {
    case DPX_COL_SPEC_SMPTE_274:
    case DPX_COL_SPEC_ITU_R_709_4:
        avctx->color_primaries = AVCOL_PRI_BT709;
        break;
    case DPX_COL_SPEC_ITU_R_601_625:
    case DPX_COL_SPEC_ITU_R_624_4_PAL:
        avctx->color_primaries = AVCOL_PRI_BT470BG;
        break;
    case DPX_COL_SPEC_ITU_R_601_525:
    case DPX_COL_SPEC_SMPTE_170:
        avctx->color_primaries = AVCOL_PRI_SMPTE170M;
        break;
    case DPX_COL_SPEC_USER_DEFINED:
    case DPX_COL_SPEC_UNSPECIFIED_VIDEO:
        /* Nothing to do */
        break;
    default:
        av_log(avctx, AV_LOG_VERBOSE, "Cannot map DPX color specification "
            "%d to color_primaries.\n", color_spec);
        break;
    }

    if (yuv) {
        switch (color_spec) {
        case DPX_COL_SPEC_SMPTE_274:
        case DPX_COL_SPEC_ITU_R_709_4:
            avctx->colorspace = AVCOL_SPC_BT709;
            break;
        case DPX_COL_SPEC_ITU_R_601_625:
        case DPX_COL_SPEC_ITU_R_624_4_PAL:
            avctx->colorspace = AVCOL_SPC_BT470BG;
            break;
        case DPX_COL_SPEC_ITU_R_601_525:
        case DPX_COL_SPEC_SMPTE_170:
            avctx->colorspace = AVCOL_SPC_SMPTE170M;
            break;
        case DPX_COL_SPEC_USER_DEFINED:
        case DPX_COL_SPEC_UNSPECIFIED_VIDEO:
            /* Nothing to do */
            break;
        default:
            av_log(avctx, AV_LOG_INFO, "Cannot map DPX color specification "
                "%d to colorspace.\n", color_spec);
            break;
        }
    } else {
        avctx->colorspace = AVCOL_SPC_RGB;
    }

    // Table 3c: Runs will always break at scan line boundaries. Packing
    // will always break to the next 32-bit word at scan-line boundaries.
    // Unfortunately, the encoder produced invalid files, so attempt
    // to detect it
    need_align = FFALIGN(stride, 4);
    if (need_align*avctx->height + (int64_t)offset > avpkt->size) {
        // Alignment seems unappliable, try without
        if (stride*avctx->height + (int64_t)offset > avpkt->size) {
            av_log(avctx, AV_LOG_ERROR, "Overread buffer. Invalid header?\n");
            return AVERROR_INVALIDDATA;
        } else {
            av_log(avctx, AV_LOG_INFO, "Decoding DPX without scanline "
                   "alignment.\n");
            need_align = 0;
        }
    } else {
        need_align -= stride;
        stride = FFALIGN(stride, 4);
    }

    switch (1000 * descriptor + 10 * bits_per_color + endian) {
    case 1081:
    case 1080:
    case 2081:
    case 2080:
    case 3081:
    case 3080:
    case 4081:
    case 4080:
    case 6081:
    case 6080:
        avctx->pix_fmt = AV_PIX_FMT_GRAY8;
        break;
    case 6121:
    case 6120:
        avctx->pix_fmt = AV_PIX_FMT_GRAY12;
        break;
    case 1320:
    case 2320:
    case 3320:
    case 4320:
    case 6320:
        avctx->pix_fmt = AV_PIX_FMT_GRAYF32LE;
        break;
    case 1321:
    case 2321:
    case 3321:
    case 4321:
    case 6321:
        avctx->pix_fmt = AV_PIX_FMT_GRAYF32BE;
        break;
    case 50081:
    case 50080:
        avctx->pix_fmt = AV_PIX_FMT_RGB24;
        break;
    case 52081:
    case 52080:
        avctx->pix_fmt = AV_PIX_FMT_ABGR;
        break;
    case 51081:
    case 51080:
        avctx->pix_fmt = AV_PIX_FMT_RGBA;
        break;
    case 50100:
    case 50101:
        avctx->pix_fmt = AV_PIX_FMT_GBRP10;
        break;
    case 51100:
    case 51101:
        avctx->pix_fmt = AV_PIX_FMT_GBRAP10;
        break;
    case 50120:
    case 50121:
        avctx->pix_fmt = AV_PIX_FMT_GBRP12;
        break;
    case 51120:
    case 51121:
        avctx->pix_fmt = AV_PIX_FMT_GBRAP12;
        break;
    case 6100:
    case 6101:
        avctx->pix_fmt = AV_PIX_FMT_GRAY10;
        break;
    case 6161:
        avctx->pix_fmt = AV_PIX_FMT_GRAY16BE;
        break;
    case 6160:
        avctx->pix_fmt = AV_PIX_FMT_GRAY16LE;
        break;
    case 50161:
        avctx->pix_fmt = AV_PIX_FMT_RGB48BE;
        break;
    case 50160:
        avctx->pix_fmt = AV_PIX_FMT_RGB48LE;
        break;
    case 51161:
        avctx->pix_fmt = AV_PIX_FMT_RGBA64BE;
        break;
    case 51160:
        avctx->pix_fmt = AV_PIX_FMT_RGBA64LE;
        break;
    case 50320:
        avctx->pix_fmt = AV_PIX_FMT_GBRPF32LE;
        break;
    case 50321:
        avctx->pix_fmt = AV_PIX_FMT_GBRPF32BE;
        break;
    case 51320:
        avctx->pix_fmt = AV_PIX_FMT_GBRAPF32LE;
        break;
    case 51321:
        avctx->pix_fmt = AV_PIX_FMT_GBRAPF32BE;
        break;
    case 100081:
        avctx->pix_fmt = AV_PIX_FMT_UYVY422;
        break;
    case 102081:
        avctx->pix_fmt = AV_PIX_FMT_YUV444P;
        break;
    case 103081:
        avctx->pix_fmt = AV_PIX_FMT_YUVA444P;
        break;
    default:
        av_log(avctx, AV_LOG_ERROR, "Unsupported format %d\n",
               1000 * descriptor + 10 * bits_per_color + endian);
        return AVERROR_PATCHWELCOME;
    }

    ff_set_sar(avctx, avctx->sample_aspect_ratio);

    if ((ret = ff_get_buffer(avctx, p, 0)) < 0)
        return ret;

    av_strlcpy(creator, avpkt->data + 160, 100);
    creator[100] = '\0';
    av_dict_set(&p->metadata, "Creator", creator, 0);

    av_strlcpy(input_device, avpkt->data + 1556, 32);
    input_device[32] = '\0';
    av_dict_set(&p->metadata, "Input Device", input_device, 0);

    // Some devices do not pad 10bit samples to whole 32bit words per row
    if (!memcmp(input_device, "Scanity", 7) ||
        !memcmp(creator, "Lasergraphics Inc.", 18)) {
        unpadded_10bit = 1;
    }

    // Move pointer to offset from start of file
    buf =  avpkt->data + offset;

    for (i=0; i<AV_NUM_DATA_POINTERS; i++)
        ptr[i] = p->data[i];

    switch (bits_per_color) {
    case 10:
        for (x = 0; x < avctx->height; x++) {
            uint16_t *dst[4] = {(uint16_t*)ptr[0],
                                (uint16_t*)ptr[1],
                                (uint16_t*)ptr[2],
                                (uint16_t*)ptr[3]};
            int shift = elements > 1 ? packing == 1 ? 22 : 20 : packing == 1 ? 2 : 0;
            for (y = 0; y < avctx->width; y++) {
                if (elements >= 3)
                    *dst[2]++ = read10in32(&buf, &rgbBuffer,
                                           &n_datum, endian, shift);
                if (elements == 1)
                    *dst[0]++ = read10in32_gray(&buf, &rgbBuffer,
                                                &n_datum, endian, shift);
                else
                    *dst[0]++ = read10in32(&buf, &rgbBuffer,
                                           &n_datum, endian, shift);
                if (elements >= 2)
                    *dst[1]++ = read10in32(&buf, &rgbBuffer,
                                           &n_datum, endian, shift);
                if (elements == 4)
                    *dst[3]++ =
                    read10in32(&buf, &rgbBuffer,
                               &n_datum, endian, shift);
            }
            if (!unpadded_10bit)
                n_datum = 0;
            for (i = 0; i < elements; i++)
                ptr[i] += p->linesize[i];
        }
        break;
    case 12:
        for (x = 0; x < avctx->height; x++) {
            uint16_t *dst[4] = {(uint16_t*)ptr[0],
                                (uint16_t*)ptr[1],
                                (uint16_t*)ptr[2],
                                (uint16_t*)ptr[3]};
            int shift = packing == 1 ? 4 : 0;
            for (y = 0; y < avctx->width; y++) {
                if (packing) {
                    if (elements >= 3)
                        *dst[2]++ = read16(&buf, endian) >> shift & 0xFFF;
                    *dst[0]++ = read16(&buf, endian) >> shift & 0xFFF;
                    if (elements >= 2)
                        *dst[1]++ = read16(&buf, endian) >> shift & 0xFFF;
                    if (elements == 4)
                        *dst[3]++ = read16(&buf, endian) >> shift & 0xFFF;
                } else {
                    if (elements >= 3)
                        *dst[2]++ = read12in32(&buf, &rgbBuffer,
                                               &n_datum, endian);
                    *dst[0]++ = read12in32(&buf, &rgbBuffer,
                                           &n_datum, endian);
                    if (elements >= 2)
                        *dst[1]++ = read12in32(&buf, &rgbBuffer,
                                               &n_datum, endian);
                    if (elements == 4)
                        *dst[3]++ = read12in32(&buf, &rgbBuffer,
                                               &n_datum, endian);
                }
            }
            n_datum = 0;
            for (i = 0; i < elements; i++)
                ptr[i] += p->linesize[i];
            // Jump to next aligned position
            buf += need_align;
        }
        break;
    case 32:
        if (elements == 1) {
            av_image_copy_plane(ptr[0], p->linesize[0],
                                buf, stride,
                                elements * avctx->width * 4, avctx->height);
        } else {
            for (y = 0; y < avctx->height; y++) {
                ptr[0] = p->data[0] + y * p->linesize[0];
                ptr[1] = p->data[1] + y * p->linesize[1];
                ptr[2] = p->data[2] + y * p->linesize[2];
                ptr[3] = p->data[3] + y * p->linesize[3];
                for (x = 0; x < avctx->width; x++) {
                    AV_WN32(ptr[2], AV_RN32(buf));
                    AV_WN32(ptr[0], AV_RN32(buf + 4));
                    AV_WN32(ptr[1], AV_RN32(buf + 8));
                    if (avctx->pix_fmt == AV_PIX_FMT_GBRAPF32BE ||
                        avctx->pix_fmt == AV_PIX_FMT_GBRAPF32LE) {
                        AV_WN32(ptr[3], AV_RN32(buf + 12));
                        buf += 4;
                        ptr[3] += 4;
                    }

                    buf += 12;
                    ptr[2] += 4;
                    ptr[0] += 4;
                    ptr[1] += 4;
                }
            }
        }
        break;
    case 16:
        elements *= 2;
    case 8:
        if (   avctx->pix_fmt == AV_PIX_FMT_YUVA444P
            || avctx->pix_fmt == AV_PIX_FMT_YUV444P) {
            for (x = 0; x < avctx->height; x++) {
                ptr[0] = p->data[0] + x * p->linesize[0];
                ptr[1] = p->data[1] + x * p->linesize[1];
                ptr[2] = p->data[2] + x * p->linesize[2];
                ptr[3] = p->data[3] + x * p->linesize[3];
                for (y = 0; y < avctx->width; y++) {
                    *ptr[1]++ = *buf++;
                    *ptr[0]++ = *buf++;
                    *ptr[2]++ = *buf++;
                    if (avctx->pix_fmt == AV_PIX_FMT_YUVA444P)
                        *ptr[3]++ = *buf++;
                }
            }
        } else {
        av_image_copy_plane(ptr[0], p->linesize[0],
                            buf, stride,
                            elements * avctx->width, avctx->height);
        }
        break;
    }

    *got_frame = 1;

    return buf_size;
}
```

Create a code snippet to fill in the masked region. Please wrap your answer in a code block (triple backquotes).